[
["index.html", "Reproducible Research Data &amp; Project Management in R Course description Learning Outcomes Course Outline Optional", " Reproducible Research Data &amp; Project Management in R Course Instructor: Anna Krystalli Mar-Apr 2020 Course description In order to ensure robustness of outputs and maximise the benefits of ACCE research to future researchers and society more generally, it is important to share the underlying code and data. But for sharing to have any impact, such materials need to be created FAIR (findable, accessible, interoperable, reusable), i.e. they must be adequately described, archived, and made discoverable to an appropriate standard. Additionally, if analyses are to be deemed robust, they must be at the very least reproducible, but ideally well documented and reviewable. R and Rstudio tools and conventions offer a powerful framework for making modern, open, reproducible and collaborative computational workflows more accessible to researchers. This course focuses on data and project management through R and Rstudio, will introduce students to best practice and equip them with modern tools and techniques for managing data and computational workflows to their full potential. The course is designed to be relevant to students with a wide range of backgrounds, working with anything from relatively small sets of data collected from field or experimental observations, to those taking a more computational approach and bigger datasets. Learning Outcomes By the end of the workshop, participants will be able to: Understand the basics of good research data management and be able to produce clean datasets with appropriate metadata. Manage computational projects for reproducibility, reuse and collaboration. Use version control to track the evolution of research projects. Use R tools and conventions to document code and analyses and produce reproducible reports. Be able to publish, share materials and collaborate through the web. Understand why this all matters! Course Outline Welcome Introduction Basics Intro to R &amp; Rstudio R basics Data types, structures &amp; classes Indexing and Subsetting The tidyverse way Data management basics Project Management Projects in Rstudio Good File Naming Paths and projects structure Data Munging Iteration Combining tables Functions Research Data Management - Metadata Literate Programming with Rmarkdown Version Control with Git Metadata Intro to metadata Creating metadata with dataspice Analysing &amp; presenting data Plotting basics Literate programming Version Control Version control with Git Collaboration through GitHub Optional Packaging code Writing &amp; documenting functions Capturing metadata incl. dependencies Checking &amp; Testing functions Putting it all together: a Research Compendium Creating a research compendium This work is licensed under a Creative Commons Attribution 4.0 International License. "],
["welcome-1.html", "Welcome", " Welcome View Slides "],
["basics.html", "(PART) Basics", " (PART) Basics "],
["rstudio-basics.html", "Intro to R &amp; Rstudio R Rstudio Working with R in Rstudio cloud", " Intro to R &amp; Rstudio R R is an open source language and environment for statistical computing and graphics. Features Powerful analytical tools, well suited to scientific analyses and data science. Analyses are performed using scripted commands, making them easy to record, edit, rerun. Source code is open, ie available to access, inspect, modify remix and publish derivatives. Large, active creative communities around development and training. Ecosystem constantly under development with continuous improvements. Install R R Environment includes: an effective data handling and storage facility, a suite of operators for calculations on arrays, a large, coherent, integrated collection of intermediate tools for data analysis, graphical facilities for data analysis and display either on-screen or on hardcopy, a well-developed, simple and effective programming language which includes conditionals, loops, user-defined functions and input and output facilities. Rstudio integrated development environment (IDE) for R Features console syntax-highlighting editor that supports direct code execution, as well as tools for: plotting debugging workspace management Find out more Working with R in Rstudio cloud We will be working online in RStudio Cloud throughout the course so we can all work in the same computational environment. This will save a lot of time by avoiding having to debug individual installation problems. To start working in R and Rstudio, we need to log in to Rstudio cloud: Launch Rstudio Cloud This will normally end up with logging you into your account workspace. To start working in R, we need to create a new project. Click on New Project This creates and deploys a new untitled Rstudio cloud project in your Workspace. Edit the project names by clicking on Untitled. Name it something like r_basics We are now in Rstudio, running in the cloud and can start running R code! "],
["r-basics.html", "R Basics Using R in the console Working in scripts Using R as a calculator Mathematical functions Variables and assignment Comparing things", " R Basics Using R in the console The most basic way to interact with R is to type code directly in the console type expression to evaluate hit return output of the evaluation of the expression is printed to the console below The simplest thing you could do with R is do arithmetic. 1 + 100 ## [1] 101 If you type in an incomplete command, R will wait for you to complete it: 1 + + Any time you hit return and the R session shows a + instead of a &gt;, it means it’s waiting for you to complete the command. If you want to cancel a command you can hit Esc and RStudio will give you back the &gt; prompt. Working in scripts To make code and workflow reproducible and easy to re-run, it’s better to save code in a script and use the script editor to edit it. This way, there is a complete record of te analysis. Creating a new script Click on File &gt; New File &gt; R Script. Click on the save icon or (like any other file) using keyboard shortcut CTRL / CMD + S Executing commands from scripts RStudio allows you to execute commands directly from the script editor by using Ctrl + Enter shortcut (on Macs, Cmd + Return will work, too). When you execute command from a script, the line of code in the script indicated by the cursor or all of the commands in the currently highlighted will be sent to the console. You can find other keyboard shortcuts in Tools &gt; Keyboard Shortcuts Help or in the RStudio IDE cheatsheet. Comments You can add comments to your code by using a hash symbol #. Any text on a line of code following # is ignored by R when it executes code. 1 + 10 # this text does nothing ## [1] 11 Using R as a calculator When using R as a calculator, the order of operations is the same as you would have learned back in school. From highest to lowest precedence: Parentheses: (, ) Exponents: ^ or ** Multiply: * Divide: / Add: + Subtract: - 3 + 5 * 2 ## [1] 13 Use parentheses to group operations in order to force the order of evaluation if it differs from the default, or to make clear what you intend. (3 + 5) * 2 ## [1] 16 Really small or large numbers get a scientific notation: 2/10000 ## [1] 2e-04 Which is shorthand for “multiplied by 10^XX”. So 2e-4 is shorthand for 2 * 10^(-4). You can write numbers in scientific notation too: 5e3 # Note the lack of minus here ## [1] 5000 Mathematical functions R has many built in mathematical functions. To call a function, we can type its name, followed by open and closing parentheses. Anything we type inside the parentheses is called the function’s arguments: sin(1) # trigonometry functions ## [1] 0.841471 log(1) # natural logarithm ## [1] 0 log10(10) # base-10 logarithm ## [1] 1 exp(0.5) # e^(1/2) ## [1] 1.648721 Don’t worry about trying to remember every function in R. You can look them up on Google, or if you can remember the start of the function’s name, use the tab completion in RStudio. This is one advantage that RStudio has over R on its own, it has auto-completion abilities that allow you to more easily look up functions, their arguments, and the values that they take. Typing a ? before the name of a command will open the help page for that command. As well as providing a detailed description of the command and how it works, scrolling to the bottom of the help page will usually show a collection of code examples which illustrate command usage. We’ll go through an example later. Variables and assignment We can store values in variables using the assignment operator &lt;-, like this: x &lt;- 1/40 Notice that assignment does not print a value. Instead, we stored it for later in something called a variable. x now contains the value 0.025: x ## [1] 0.025 Look for the Environment tab in one of the panes of RStudio, and you will see that x and its value have appeared. Our variable x can be used in place of a number in any calculation that expects a number: log(x) ## [1] -3.688879 Notice also that variables can be reassigned: x &lt;- 100 x used to contain the value 0.025 and now it has the value 100. Assignment values can contain the variable being assigned to: x &lt;- x + 1 #notice how RStudio updates its description of x on the top right tab y &lt;- x * 2 The right hand side of the assignment can be any valid R expression. The right hand side is fully evaluated before the assignment occurs. It is also possible to use the = operator for assignment: x = 1/40 But this is much less common among R users. The most important thing is to be consistent with the operator you use. There are occasionally places where it is less confusing to use &lt;- than =, and it is the most common symbol used in the community. So the recommendation is to use &lt;-. On variable names Variable names can contain letters, numbers, underscores and periods. They cannot start with a number nor contain spaces at all. Different people use different conventions for long variable names, these include periods.between.words camelCaseToSeparateWords snake_case: underscores_between_words While I suggest you use snake_case, ultimately what you use is up to you, but be consistent. Comparing things We can also do comparison in R: x &lt;- 1 x &lt; 2 # less than ## [1] TRUE x &lt;= 1 # less than or equal to ## [1] TRUE x &gt; 0 # greater than ## [1] TRUE x &gt;= -9 # greater than or equal to ## [1] TRUE x == 1 # equality (note two equals signs, read as &quot;is equal to&quot;) ## [1] TRUE 1 != 2 # inequality (read as &quot;is not equal to&quot;) ## [1] TRUE x %in% c(1, 5) # membership (read as &quot;is member of&quot;) ## [1] TRUE A word of warning about comparing numbers: you should never use == to compare two numbers unless they are integers (a data type which can specifically represent only whole numbers). Controlling flow using logical statements Comparing a single value results in TRUE or FALSE. This feature allows us to build conditional statements to control execution flow. if(x &gt; 5){ print(&quot;x is greater than 5&quot;) }else{ print(&quot;x is less than 5&quot;) } ## [1] &quot;x is less than 5&quot; "],
["data-types-structures-and-classes.html", "Data types, structures and classes Base types Base data types Data Structures Lists Data.frames", " Data types, structures and classes Base types Every object has a base type and only R-core can create new types. Over all there are 25 different base object types. Base data types There are 5 base data types: double, integer, complex, logical, character as well as NULL. No matter how complicated your analyses become, all data in R is interpreted as one of these basic data types. You can inspect the type of a value or object through function typeof(). typeof(3.14) ## [1] &quot;double&quot; typeof(1L) # The L suffix forces the number to be an integer, since by default R uses float numbers ## [1] &quot;integer&quot; typeof(TRUE) ## [1] &quot;logical&quot; typeof(&#39;banana&#39;) ## [1] &quot;character&quot; typeof(NULL) ## [1] &quot;NULL&quot; Data Structures Arrays and type coersion The distinguishing feature of arrays is that all values are of the same data type. Arrays can take values of any base data type and span any number of dimensions. However, all values must be of the same base data type. This allows for efficent calculation and matrix mathematics. The strictness also has some really important consequences which introduces another key concept in R, that of type coersion. Vectors and Type Coercion Vectors Vectors are one dimensional arrays. To better understand the importance of data types and coersion, let’s meet a special case of an array, the vector. To create a new vector use function vector(). You can specify the length of the vector with argument length and the base data type through my_vector &lt;- vector(length = 3) my_vector ## [1] FALSE FALSE FALSE A vector in R is essentially an ordered list of things, with the special condition that everything in the vector must be the same basic data type. typeof(my_vector) ## [1] &quot;logical&quot; If you don’t choose the datatype, it’ll default to logical; or, you can declare an empty vector of whatever type you like. another_vector &lt;- vector(mode=&#39;character&#39;, length=3) another_vector ## [1] &quot;&quot; &quot;&quot; &quot;&quot; You can also make series of numbers: 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 seq(10) ## [1] 1 2 3 4 5 6 7 8 9 10 seq(1,10, by=0.1) ## [1] 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3 2.4 ## [16] 2.5 2.6 2.7 2.8 2.9 3.0 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 ## [31] 4.0 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5.0 5.1 5.2 5.3 5.4 ## [46] 5.5 5.6 5.7 5.8 5.9 6.0 6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 ## [61] 7.0 7.1 7.2 7.3 7.4 7.5 7.6 7.7 7.8 7.9 8.0 8.1 8.2 8.3 8.4 ## [76] 8.5 8.6 8.7 8.8 8.9 9.0 9.1 9.2 9.3 9.4 9.5 9.6 9.7 9.8 9.9 ## [91] 10.0 You can also create vectors by combining individual elements using function c (for combine). combine_vector &lt;- c(2,6,3) combine_vector ## [1] 2 6 3 Type coercion Q: Given what we’ve learned so far, what do you think the following will produce? c(2,6,&#39;3&#39;) ## [1] &quot;2&quot; &quot;6&quot; &quot;3&quot; This is something called type coercion, and it is the source of many surprises and the reason why we need to be aware of the basic data types and how R will interpret them. When R encounters a mix of types (here numeric and character) to be combined into a single vector, it will force them all to be the same type. Not all types can be coerced into another, rather, R has a coercion hierarchy rule. All values are converted to the lowest data type in the hierarchy. R coercion rules: logical -&gt; integer -&gt; numeric -&gt; complex -&gt; character where -&gt; can be read as “are transformed into”. In our case, our 2, &amp; 3 integer values where converted to character. Some other examples: c(&#39;a&#39;, TRUE) ## [1] &quot;a&quot; &quot;TRUE&quot; c(&quot;FALSE&quot;, TRUE) ## [1] &quot;FALSE&quot; &quot;TRUE&quot; c(0, TRUE) ## [1] 0 1 You can try to force coercion against this flow using the as. functions: chars &lt;- c(&#39;0&#39;,&#39;2&#39;,&#39;4&#39;) as.numeric(chars) ## [1] 0 2 4 as.logical(chars) ## [1] NA NA NA as.logical(as.numeric(chars)) ## [1] FALSE TRUE TRUE as.logical(c(0, TRUE)) ## [1] FALSE TRUE as.logical(c(&quot;FALSE&quot;, TRUE)) ## [1] FALSE TRUE as.numeric(c(&quot;FALSE&quot;, TRUE)) ## Warning: NAs introduced by coercion ## [1] NA NA as.numeric(as.logical(c(&quot;FALSE&quot;, TRUE))) ## [1] 0 1 As you can see, some surprising things can happen when R forces one basic data type into another! If your data isn’t the data type you expected, type coercion may well be to blame; make sure everything is the same type in your vectors and your columns of data.frames, or you will get nasty surprises! We can ask a few questions about vectors: sequence_example &lt;- seq(10) head(sequence_example, n=2) ## [1] 1 2 tail(sequence_example, n=4) ## [1] 7 8 9 10 length(sequence_example) ## [1] 10 str(sequence_example) ## int [1:10] 1 2 3 4 5 6 7 8 9 10 The somewhat cryptic output from this command indicates the basic data type found in this vector - in this case chr, character; an indication of the number of things in the vector - actually, the indexes of the vector, in this case [1:3]; and a few examples of what’s actually in the vector - in this case empty character strings. If we similarly do Finally, you can give names to elements in your vector: my_example &lt;- 5:8 names(my_example) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) my_example ## a b c d ## 5 6 7 8 names(my_example) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; Find out more about vectors Matrices Matrices are 2 dimensional arrays The dimensions are defined by the number of rows and columns. We can declare a matrix full of zeros: matrix_example &lt;- matrix(0, ncol=6, nrow=3) matrix_example ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0 0 0 0 0 0 ## [2,] 0 0 0 0 0 0 ## [3,] 0 0 0 0 0 0 We can get the dimensions of a matrix (or any array with dimensions &gt; 1). dim(matrix_example) ## [1] 3 6 Lists Lists can store objects of any data type and class Another key data structure is the list. List are the most flexible data structure because each element can hold any object, of any datat type and dimension, including other lists. Create lists using list() or coerce other objects using as.list(). list(1, &quot;a&quot;, TRUE) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] &quot;a&quot; ## ## [[3]] ## [1] TRUE as.list(1:4) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 ## ## [[4]] ## [1] 4 We can name list elements: a_list &lt;- list(title = &quot;Numbers&quot;, numbers = 1:10, data = TRUE ) a_list ## $title ## [1] &quot;Numbers&quot; ## ## $numbers ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## $data ## [1] TRUE Lists are a base type: typeof(a_list) ## [1] &quot;list&quot; Data.frames S3, S4 and S6 objects Arrays and lists are all immutable base types. However, there are other types of objects in R. These are S3, S4 &amp; S6 type objects, with S3 being the most common. Such objects have a class attribute (base types can have a class attribute too), enabling class specific functionality, a characteristic of object oriented programming. New classes can be created by users, allowing greater flexibility in the types of data structures available for analyses. Learn more about object types Data.frames The most important S3 object class in R is the data.frame. Data.frames are special types of lists. Data.frames are special types of lists where each element is a vector, each of equal length. So each column of a data.frame contains values of consistent data type but the data type can vary between columns (ie along rows). df &lt;- data.frame(id = 1:3, treatment = c(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;), complete = c(TRUE, TRUE, FALSE)) df ## id treatment complete ## 1 1 a TRUE ## 2 2 b TRUE ## 3 3 b FALSE We can check that our data.frame is a list under the hood: typeof(df) ## [1] &quot;list&quot; As an S3 object, it also has a class attribute: class(df) ## [1] &quot;data.frame&quot; And we can check the type of object that it is: sloop::otype(df) ## [1] &quot;S3&quot; Compared to a vector? sloop::otype(1:10) ## [1] &quot;base&quot; We can check the dimensions of a data.frame dim(df) ## [1] 3 3 Get a certain number of rows from the top or bottom head(df, 1) ## id treatment complete ## 1 1 a TRUE tail(df, 1) ## id treatment complete ## 3 3 b FALSE Importantly, we can disply the structure of a data.frame str(df) ## &#39;data.frame&#39;: 3 obs. of 3 variables: ## $ id : int 1 2 3 ## $ treatment: Factor w/ 2 levels &quot;a&quot;,&quot;b&quot;: 1 2 2 ## $ complete : logi TRUE TRUE FALSE A note on factors Note that the default behaviour of data.frame() is to covert character vectors to factors. Factors are another important data structure for handling categorical data, which have particular statistical properties. They can be useful during modeling and plotting but in the interest of time we will not be discuss them further here. You can suppress R default behaviour using: df &lt;- data.frame(id = 1:3, treatment = c(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;), complete = c(TRUE, TRUE, FALSE), stringsAsFactors = FALSE) str(df) ## &#39;data.frame&#39;: 3 obs. of 3 variables: ## $ id : int 1 2 3 ## $ treatment: chr &quot;a&quot; &quot;b&quot; &quot;b&quot; ## $ complete : logi TRUE TRUE FALSE Find out more about factors. "],
["indexing-and-subsetting.html", "Indexing and subsetting Subsetting vectors Matrix subsetting Subsetting lists Subsetting data.frames Advanced R Cheat Sheet", " Indexing and subsetting R has many powerful subset operators. Mastering them will allow you to easily perform complex operations on any kind of dataset. There many different ways we can subset any kind of object, and three different subsetting operators for the different data structures. Subsetting vectors Let’s start by examining subsetting in the simplest data structure, the vector. Subsetting a vector always returns another vector. x &lt;- 4:7 x ## [1] 4 5 6 7 Subsetting using [ and elements indices Extracting single elements To extract elements of a vector we can use the square bracket operator ([) and the target element index, starting from one: x[1] ## [1] 4 x[4] ## [1] 7 It may look different, but the square brackets operator is a function and means “get me the nth element”. If we ask for an index beyond the length of the vector, R will return a missing value: x[6] ## [1] NA If we ask for the 0th element, we get an empty vector: x[0] ## integer(0) Extracting multiple elements We can also ask for multiple elements at once: x[c(1, 3)] ## [1] 4 6 Or slices of the vector: x[2:4] ## [1] 5 6 7 We can ask for the same element multiple times: x[c(1,1,3)] ## [1] 4 4 6 Excluding and removing elements If we use a negative number as the index of a vector, R will return every element except for the one specified: x[-2] ## [1] 4 6 7 We can skip multiple elements: x[c(-1, -5)] # or x[-c(1,5)] ## [1] 5 6 7 In general, e aware that the result of subsetting using indices could change if the vector is reordered. Subsetting using element names If the vector has a name attribute, we can subset the vector more precisely using the element’s name names(x) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) x[c(&quot;a&quot;, &quot;c&quot;)] ## a c ## 4 6 Subsetting using names in the most robust way to extract elements. The position of various elements can often change when chaining together subsetting operations, but the names will always remain the same! Subsetting using logical vectors We can also use any logical vector to subset: x[c(FALSE, FALSE, TRUE, TRUE)] ## c d ## 6 7 Since comparison operators (e.g. &gt;, &lt;, ==) evaluate to logical vectors, we can also use them to succinctly subset vectors: the following statement gives the same result as the previous one. x[x &gt; 5] ## c d ## 6 7 Breaking it down, this statement first evaluates x &gt; 5, generating a logical vector c(FALSE, FALSE, TRUE, TRUE), and then selects the elements of x corresponding to the TRUE values. We can use == to mimic the previous method of indexing by name (remember you have to use == rather than = for comparisons): x[names(x) == &quot;a&quot;] ## a ## 4 Avoid using == to compare numbers! See function dplyr::near() instead. We also might want to subset using a vector of potential values, that might not necessarily have matches in x. In this case we can use %in% x[names(x) %in% c(&quot;a&quot;, &quot;c&quot;, &quot;e&quot;)] ## a c ## 4 6 Excluding named elements Excluding or removing named elements is a little harder. If we try to skip one named element by negating the string, R complains (slightly obscurely) that it doesn’t know how to take the negative of a string: x[-&quot;a&quot;] ## Error in -&quot;a&quot;: invalid argument to unary operator However, we can use the != (not-equals) operator to construct a logical vector that will do what we want: x[names(x) != &quot;a&quot;] ## b c d ## 5 6 7 Excluding multiple named indices requires a different tactic through. Suppose we want to drop the &quot;a&quot; and &quot;c&quot; elements, so we try this: x[names(x) != c(&quot;a&quot;,&quot;c&quot;)] ## b c d ## 5 6 7 R did something, but it gave us a warning that we ought to pay attention to - and it apparently gave us the wrong answer (the &quot;c&quot; element is still included in the vector)! This happens because we are trying to compare two vectors (names(x) and c(&quot;a&quot;,&quot;c&quot;)) and comparison operators are automatically vectorised in such a case. So in effect, R is comparing &quot;a&quot; in names(x) to &quot;a&quot; in c(&quot;a&quot;,&quot;c&quot;) and returning FALSE (ie &quot;a&quot; != &quot;a&quot; = FALSE), then &quot;b&quot; in names(x) to &quot;c&quot; in c(&quot;a&quot;,&quot;c&quot;) and returning TRUE. What happens with &quot;c&quot; in names(x) is R recuycles the comparison vector c(&quot;a&quot;,&quot;c&quot;) and starts again with &quot;a&quot;. &quot;c&quot; is not equal to &quot;a&quot; so &quot;a&quot; != &quot;c&quot; returns TRUE and the element is kept. On the other hand this works, but only by chance: x[names(x) != c(&quot;a&quot;,&quot;b&quot;)] ## c d ## 6 7 To perform such a subset robustly, we need to combine %in% and !. x[!names(x) %in% c(&quot;a&quot;,&quot;c&quot;)] ## b d ## 5 7 This checks whether names of x take any value of the values in c(&quot;a&quot;,&quot;c&quot;), returning the elements where the condition is TRUE. The ! then negates the selection, returning only the elements whose names are not contained in c(&quot;a&quot;,&quot;c&quot;). Matrix subsetting As matrices are just 2d vectors, all the subsetting operations using the [ can also be applied to matrices. Subsetting using element indices Let’s create a matrix m &lt;- matrix(1:12, ncol=4, nrow=3) m ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 Indexing matrices with [ takes two arguments: the first expression is applied to the rows, the second to the columns: Say we want the 2 and 3rd rows of the last and first column (in that order) of our matrix. We can use all the subsetting we learned for vectors and apply them to each dimension of our matrix. m[2:3, c(4,1)] ## [,1] [,2] ## [1,] 11 2 ## [2,] 12 3 Subsetting whole rows or columns We can leave the first or second arguments blank to retrieve all the rows or columns respectively: m[, c(2,3)] ## [,1] [,2] ## [1,] 4 7 ## [2,] 5 8 ## [3,] 6 9 m[c(2,3),] ## [,1] [,2] [,3] [,4] ## [1,] 2 5 8 11 ## [2,] 3 6 9 12 If we only access one row or column, R will automatically convert the result to a vector: m[3,] ## [1] 3 6 9 12 If we want to keep the output as a matrix, we need to specify a third argument; drop = FALSE: m[3, , drop=FALSE] ## [,1] [,2] [,3] [,4] ## [1,] 3 6 9 12 Tip: Higher dimensional arrays When dealing with multi-dimensional arrays, each argument to [ corresponds to a dimension. For example, a 3D array, the first three arguments correspond to the rows, columns, and depth dimension. Subsetting lists There are three functions used to subset lists and extract individual elements: [, [[, and $. Subsetting list elements Using [ will always return a list. If you want to subset a list, but not extract an element, then you will likely use [. xlist &lt;- list(a = &quot;ACCE DTP&quot;, b = 1:10, data = head(iris)) Subsetting by element indices As with vectors, we can use element indices and [ to subset lists. xlist[1] ## $a ## [1] &quot;ACCE DTP&quot; This returns a list with one element. We can use multiple indices to subset multiple list elements: xlist[1:2] ## $a ## [1] &quot;ACCE DTP&quot; ## ## $b ## [1] 1 2 3 4 5 6 7 8 9 10 Subsetting by name We can also use names: xlist[c(&quot;a&quot;, &quot;b&quot;)] ## $a ## [1] &quot;ACCE DTP&quot; ## ## $b ## [1] 1 2 3 4 5 6 7 8 9 10 It is accessing the list as if it were a vector and returning a list. Comparison operations involving the contents of list elements however won’t work as they are not accessible at the level of [ indexing. Extracting individual elements Extracting individual elements allow us to access the objects contained in a list, which can be any type of object. Hence the result depends on the object each element contains. To extract individual elements of a list, we use the double-square bracket function: [[. Extracting by element index Again we can use element indices to extract the object contained in an element. xlist[[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 Notice that now the result is a vector, not a list, which is what the second element contained. You can’t extract more than one element at once: xlist[[1:2]] ## Error in xlist[[1:2]]: subscript out of bounds Nor use it to skip elements: xlist[[-1]] ## Error in xlist[[-1]]: attempt to select more than one element in get1index &lt;real&gt; Extracting by element name We can however use single names to extract elements: xlist[[&quot;a&quot;]] ## [1] &quot;ACCE DTP&quot; The $ operator The $ operator is a shorthand way for extracting single elements by name: xlist$data ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa List subsetting challenge Given the following list: xlist &lt;- list(a = &quot;ACCE DTP&quot;, b = 1:10, data = head(iris)) and using your knowledge of both list and vector subsetting, extract the number 2 from xlist. Hint: the number 2 is contained within the “b” item in the list. Solution Subsetting data.frames Data frames are lists underneath the hood, so similar rules apply subsetting rules apply. However they are also two dimensional objects. Subsetting data.frames as a list Using [ to subset Using the [ operator with one argument will act the same way as for lists, where each list element corresponds to a column. The resulting object will be a data.frame: trees[1] ## Girth ## 1 8.3 ## 2 8.6 ## 3 8.8 ## 4 10.5 ## 5 10.7 ## 6 10.8 ## 7 11.0 ## 8 11.0 ## 9 11.1 ## 10 11.2 ## 11 11.3 ## 12 11.4 ## 13 11.4 ## 14 11.7 ## 15 12.0 ## 16 12.9 ## 17 12.9 ## 18 13.3 ## 19 13.7 ## 20 13.8 ## 21 14.0 ## 22 14.2 ## 23 14.5 ## 24 16.0 ## 25 16.3 ## 26 17.3 ## 27 17.5 ## 28 17.9 ## 29 18.0 ## 30 18.0 ## 31 20.6 trees[&quot;Girth&quot;] ## Girth ## 1 8.3 ## 2 8.6 ## 3 8.8 ## 4 10.5 ## 5 10.7 ## 6 10.8 ## 7 11.0 ## 8 11.0 ## 9 11.1 ## 10 11.2 ## 11 11.3 ## 12 11.4 ## 13 11.4 ## 14 11.7 ## 15 12.0 ## 16 12.9 ## 17 12.9 ## 18 13.3 ## 19 13.7 ## 20 13.8 ## 21 14.0 ## 22 14.2 ## 23 14.5 ## 24 16.0 ## 25 16.3 ## 26 17.3 ## 27 17.5 ## 28 17.9 ## 29 18.0 ## 30 18.0 ## 31 20.6 Using [[ to extract Similarly, [[ will act to extract a single column as a vector: trees[[1]] ## [1] 8.3 8.6 8.8 10.5 10.7 10.8 11.0 11.0 11.1 11.2 11.3 11.4 11.4 11.7 12.0 ## [16] 12.9 12.9 13.3 13.7 13.8 14.0 14.2 14.5 16.0 16.3 17.3 17.5 17.9 18.0 18.0 ## [31] 20.6 trees[[&quot;Girth&quot;]] ## [1] 8.3 8.6 8.8 10.5 10.7 10.8 11.0 11.0 11.1 11.2 11.3 11.4 11.4 11.7 12.0 ## [16] 12.9 12.9 13.3 13.7 13.8 14.0 14.2 14.5 16.0 16.3 17.3 17.5 17.9 18.0 18.0 ## [31] 20.6 And $ provides a convenient shorthand to extract columns by name: trees$Girth ## [1] 8.3 8.6 8.8 10.5 10.7 10.8 11.0 11.0 11.1 11.2 11.3 11.4 11.4 11.7 12.0 ## [16] 12.9 12.9 13.3 13.7 13.8 14.0 14.2 14.5 16.0 16.3 17.3 17.5 17.9 18.0 18.0 ## [31] 20.6 Subsetting data.frames as a matrix With two arguments, [ behaves the same way as for matrices: trees[1:5, c(&quot;Girth&quot;, &quot;Volume&quot;)] ## Girth Volume ## 1 8.3 10.3 ## 2 8.6 10.3 ## 3 8.8 10.2 ## 4 10.5 16.4 ## 5 10.7 18.8 If we subset a single row, the result will be a data.frame (because the elements are mixed types): trees[3,] ## Girth Height Volume ## 3 8.8 63 10.2 But for a single column the result will be a vector. trees[, &quot;Girth&quot;] ## [1] 8.3 8.6 8.8 10.5 10.7 10.8 11.0 11.0 11.1 11.2 11.3 11.4 11.4 11.7 12.0 ## [16] 12.9 12.9 13.3 13.7 13.8 14.0 14.2 14.5 16.0 16.3 17.3 17.5 17.9 18.0 18.0 ## [31] 20.6 This can be changed with the third argument, drop = FALSE). trees[, &quot;Girth&quot;, drop=FALSE] ## Girth ## 1 8.3 ## 2 8.6 ## 3 8.8 ## 4 10.5 ## 5 10.7 ## 6 10.8 ## 7 11.0 ## 8 11.0 ## 9 11.1 ## 10 11.2 ## 11 11.3 ## 12 11.4 ## 13 11.4 ## 14 11.7 ## 15 12.0 ## 16 12.9 ## 17 12.9 ## 18 13.3 ## 19 13.7 ## 20 13.8 ## 21 14.0 ## 22 14.2 ## 23 14.5 ## 24 16.0 ## 25 16.3 ## 26 17.3 ## 27 17.5 ## 28 17.9 ## 29 18.0 ## 30 18.0 ## 31 20.6 Advanced R Cheat Sheet Figure 1: Environments, data Structures, Functions, Subsetting and more by Arianne Colton and Sean Chen "],
["the-tidyverse-way.html", "The tidyverse way Intro to the tidyverse tibbles Subsetting tibbles The pipe operator %&gt;% Advanced R Cheat Sheet", " The tidyverse way Intro to the tidyverse The Tidyverse is a coherent system of packages for data manipulation, exploration and visualization that share a common design philosophy. Advantages of the tidyverse Consistent functions. Workflow coverage. A parsimonious approach to the development of data science tools. Tidyverse Principles tibbles as main data structures. Tidy data where rows are sigle observations and columns the variables observed. Piping the outputs of tidyverse functions as inputs to subsequent functions. install.packages(c(&quot;tibble&quot;, &quot;dplyr&quot;)) tibbles tibbles are one of the unifying features of the tidyverse, and are the tidyverse version of a data.frame (I will use them interchangeably in the rest of the text). Features Better printing behaviour. Never coerces characters to factors. More robust error handling. Creating tibbles Coercing data.frames You can coerce a data.frame to a tibble tree_tbl &lt;- tibble::as_tibble(trees) tree_tbl ## # A tibble: 31 x 3 ## Girth Height Volume ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8.3 70 10.3 ## 2 8.6 65 10.3 ## 3 8.8 63 10.2 ## 4 10.5 72 16.4 ## 5 10.7 81 18.8 ## 6 10.8 83 19.7 ## 7 11 66 15.6 ## 8 11 75 18.2 ## 9 11.1 80 22.6 ## 10 11.2 75 19.9 ## # … with 21 more rows As you can see, printing tibbles is much tidier and informative and designed so that you don’t accidentally overwhelm your console when you print large data.frames. Creating new tibbles You can create a new tibble from individual vectors with tibble(). tibble() will automatically recycle inputs of length 1, and allows you to refer to variables that you just created: tibble::tibble( x = 1:5, y = 1, z = x ^ 2 + y ) ## # A tibble: 5 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 ## 2 2 1 5 ## 3 3 1 10 ## 4 4 1 17 ## 5 5 1 26 Subsetting tibbles Base R subsetting We can use all the tools we learnt to subset data.frames to subset tibbles. Subsetting using the tidyverse You can also subset tibbles using tidyverse functions from package dplyr. dplyr verbs are inspired by SQL vocabulary and designed to be more intuitive. library(dplyr) The first argument of the main dplyr functions is a tibble (or data.frame) Filtering rows with filter() filter() allows us to subset observations (rows) based on their values. The first argument is the name of the data frame. The second and subsequent arguments are the expressions that filter the data frame. filter(tree_tbl, Girth &gt; 14) ## # A tibble: 10 x 3 ## Girth Height Volume ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 14.2 80 31.7 ## 2 14.5 74 36.3 ## 3 16 72 38.3 ## 4 16.3 77 42.6 ## 5 17.3 81 55.4 ## 6 17.5 82 55.7 ## 7 17.9 80 58.3 ## 8 18 80 51.5 ## 9 18 80 51 ## 10 20.6 87 77 dplyr executes the filtering operation by generating a logical vector and returns a new tibble of the rows that match the filtering conditions. You can therefore use any logical operators we learnt using [. Slicing rows with slice() Using slice() is similar to subsetting using element indices in that we provide element indices to select rows. slice(tree_tbl, 2) ## # A tibble: 1 x 3 ## Girth Height Volume ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8.6 65 10.3 slice(tree_tbl, 2:5) ## # A tibble: 4 x 3 ## Girth Height Volume ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8.6 65 10.3 ## 2 8.8 63 10.2 ## 3 10.5 72 16.4 ## 4 10.7 81 18.8 Selecting columns with select() select() allows us to subset columns in tibbles using operations based on the names of the variables. In dplyr we use unquoted column names (ie Volume rather than &quot;Volume&quot;). select(tree_tbl, Height, Volume) ## # A tibble: 31 x 2 ## Height Volume ## &lt;dbl&gt; &lt;dbl&gt; ## 1 70 10.3 ## 2 65 10.3 ## 3 63 10.2 ## 4 72 16.4 ## 5 81 18.8 ## 6 83 19.7 ## 7 66 15.6 ## 8 75 18.2 ## 9 80 22.6 ## 10 75 19.9 ## # … with 21 more rows Behind the scenes, select matches any variable arguments to column names creating a vector of column indices. This is then used to subset the tibble. As such we can create ranges of variables using their names and : select(tree_tbl, Height:Volume) ## # A tibble: 31 x 2 ## Height Volume ## &lt;dbl&gt; &lt;dbl&gt; ## 1 70 10.3 ## 2 65 10.3 ## 3 63 10.2 ## 4 72 16.4 ## 5 81 18.8 ## 6 83 19.7 ## 7 66 15.6 ## 8 75 18.2 ## 9 80 22.6 ## 10 75 19.9 ## # … with 21 more rows There’s also a number of helper functions to make selections easier. For example, we can use one_of() to provide a character vector of column names to select. select(tree_tbl, one_of(c(&quot;Height&quot;, &quot;Volume&quot;))) ## # A tibble: 31 x 2 ## Height Volume ## &lt;dbl&gt; &lt;dbl&gt; ## 1 70 10.3 ## 2 65 10.3 ## 3 63 10.2 ## 4 72 16.4 ## 5 81 18.8 ## 6 83 19.7 ## 7 66 15.6 ## 8 75 18.2 ## 9 80 22.6 ## 10 75 19.9 ## # … with 21 more rows Find out more about dplyr helper functions The pipe operator %&gt;% Pipes are a powerful tool for clearly expressing a sequence of multiple operations. They help us write code in a way that is easier to read and understand. They also remove the need for creating intermediate objects. Pipes take the output of the evaluation of the preceeding code and pipe it as the first argument to the subsequent expression. Suppose we want to get the first two rows and only columns Girth and Volume. We can chain the two operations together using the pipe. tree_tbl %&gt;% select(Girth, Volume) %&gt;% slice(1:2) ## # A tibble: 2 x 2 ## Girth Volume ## &lt;dbl&gt; &lt;dbl&gt; ## 1 8.3 10.3 ## 2 8.6 10.3 This is form is very understandable because it focusses on intuitive verbs, not nouns. You can read this series of function compositions like it’s a set of imperative actions. As mentioned, the default behaviour of the pipe is to pipe objects as the first argument of the next expression. However, we can pipe the object into a different argument using the . operator. tree_tbl %&gt;% lm(Girth ~ Height, data = .) ## ## Call: ## lm(formula = Girth ~ Height, data = .) ## ## Coefficients: ## (Intercept) Height ## -6.1884 0.2557 Note: The pipe, %&gt;%, comes from the magrittr package by Stefan Milton Bache. Packages in the tidyverse load %&gt;% for you automatically, so you don’t usually load magrittr explicitly. Advanced R Cheat Sheet "],
["data-management-basics.html", "Data management Basics", " Data management Basics View Slides "],
["proj-management.html", "(PART) Project Management", " (PART) Project Management "],
["projects-in-rstudio.html", "Projects in Rstudio General Project Organisation Rstudio Projects Rstudio Cloud projects", " Projects in Rstudio Rstudio projects are a convenient way to manage research projects, providing the scaffolding for robust, self-contained and portable work. General Project Organisation Good project layout helps ensure: Integrity of data Portability of the project work is easy to revisit after a break and onboard new collaborators supports tool building which takes advantage of the shared structure. Principles Everything required is contained in the project or sourced automatically. Use paths relative to the project root directory. Separate data, methods, and output, while making the relationship between them clear. Document the contents of your project and how to use them. Use R package development and community conventions. Do not manually edit raw data. Keep a clean pipeline of data processing from raw to analytical. Incorporate checks to ensure correct processing and analysing. Rstudio Projects Rstudio projects are a convenient way to manage research projects, providing the scaffolding for self contained and portable work. Features Self contained and portable Clean environment on load Working directory and files tab set to project root Rstudio Cloud projects For the rest of the course, we will be working in a project where I have already set up the computational environment. This will save a lot of time by avoiding having to run a long installation scrip during the class or debug individual installation problems. Launch Rstudio Cloud project To access this project, please click on the supplied project link This should drop you into the ACCE DTP Reproducible research in R Workspace. If not, navigate to the space from the menu on the top left. In there you will find a project called wood-survey. Click on + Copy to create your own copy of the project. Once the project has been created you need to give it a name. Stick to wood-survey You now have your own version of the project. Creating projects locally To create a new project locally in Rstudio, you can either use File &gt; New Project &gt; New Directory, or in the console (you only need to run this once, so you don’t want it to be part of a repeatable script) run: usethis::create_project(&quot;~/Desktop/wood-survey&quot;) In general, do not use such hard code paths in repeatable scripts. They might not work across operating systems and are unlikely to generalise across someone elses file system. You will also need to run the install.R script. See the setup instructions for more details. "],
["good-file-naming.html", "Good File Naming", " Good File Naming View Slides "],
["paths-and-project-structure.html", "Paths and Project structure Project Data Setting up a data-raw/ directory NEON Data Paths Basic checks", " Paths and Project structure Project Data We’re in our new project so the first thing we need to do is get the data we’ll be working with. This is a common start to any project where you start with a few data files, These might be generated through your data, given by others or published data products and you might need to clean, wrangle and combine them together to perform your analysis. Q: Where should I save my raw data files? conventions: Data management Store raw data in data-raw/: raw inputs to any pre-processing, read only. Keep any processing scripts in the same folder Whether and where you publish data depends on size and copyright considerations. Store analytical data in data/: any clean, processed data that is used as the input to the analysis. Should be published along side analysis. Setting up a data-raw/ directory We start by creating a data-raw directory in the root of our project. We can use usethis function usethis::use_data_raw(). This creates the data-raw directory and an .R script within where we can save code that turns raw data into analytical data in the data/ folder. We can supply a name for the analytical dataset we’ll be creating in our script which automatically names the .R script for easy provenance tracking. In this case, we’ll be calling it individual.csv so let’s use &quot;individual&quot; for our name. usethis::use_data_raw(name = &quot;individual&quot;) ✔ Setting active project to &#39;/Users/Anna/Desktop/wood-survey&#39; ✔ Creating &#39;data-raw/&#39; ✔ Adding &#39;^data-raw$&#39; to &#39;.Rbuildignore&#39; ✔ Writing &#39;data-raw/individual.R&#39; ● Modify &#39;data-raw/individual.R&#39; ● Finish the data preparation script in &#39;data-raw/individual.R&#39; ● Use `usethis::use_data()` to add prepared data to package The data-raw/individual.R script created contains: ## code to prepare `individual` dataset goes here usethis::use_data(&quot;individual&quot;) We will use this file to perform the necessary preprocessing on our raw data. Download data Now that we’ve got our data-raw folder, let’s download our data into it using function usethis::use_course() and supplying it with the url to the materials repository (bit.ly/wood-survey-data) and the path to the directory we want the materials saved into (&quot;data-raw&quot;). usethis::use_course(&quot;bit.ly/wood-survey-data&quot;, destdir = &quot;data-raw&quot;) ✔ Downloading from &#39;https://github.com/annakrystalli/wood-survey-data/archive/master.zip&#39; Downloaded: 0.03 MB ✔ Download stored in &#39;data-raw/wood-survey-data-master.zip&#39; ✔ Unpacking ZIP file into &#39;wood-survey-data-master/&#39; (13 files extracted) Shall we delete the ZIP file (&#39;wood-survey-data-master.zip&#39;)? 1: Negative 2: Absolutely not 3: I agree Selection: 3 ✔ Deleting &#39;wood-survey-data-master.zip&#39; ✔ Opening &#39;wood-survey-data-master/&#39; in the file manager NEON Data The downloaded folder contains a subset of data from the NEON Woody plant vegetation survey. This data product was downloaded from the NEON data portal and contains quality-controlled data from in-situ measurements of live and standing dead woody individuals and shrub groups, from all terrestrial NEON sites with qualifying woody vegetation. Surveys of each site are completed once every 3 years. Let’s have a look at what we’ve downloaded: . ├── R ├── data-raw │ ├── individual.R │ └── wood-survey-data-master │ ├── NEON_vst_variables.csv │ ├── README.md │ ├── individual [67 entries exceeds filelimit, not opening dir] │ ├── methods │ │ ├── NEON.DOC.000914vB.pdf │ │ ├── NEON.DOC.000987vH.pdf │ │ └── NEON_vegStructure_userGuide_vA.pdf │ ├── vst_mappingandtagging.csv │ └── vst_perplotperyear.csv └── wood-survey.Rproj The important files for the analysis we want to perform are ├── individual [67 entries exceeds filelimit, not opening dir] ├── vst_mappingandtagging.csv └── vst_perplotperyear.csv vst_perplotperyear: Plot level metadata, including plot geolocation, one record per plotID per eventID, describe the presence/absence of woody growth forms sampling area utilized for each growth form. vst_mappingandtagging: Mapping, identifying and tagging of individual stems for remeasurement one record per individualID, data invariant through time, including tagID, taxonID and mapped location. Records can be linked to vst_perplotperyear via the plotID and eventID fields. vst_apparentindividual: Biomass and productivity measurements of apparent individuals. may contain multiple records per individuals includes growth form, structure currently in separate files contained in individual/ may be linked vst_mappingandtagging records via individualID vst_perplotperyear via the plotID and eventID fields. As our first challenge, we are going to combined all the files in individual/ into a single analytical data file! Paths First let’s investigate our data. We want to access the files so we need to give R paths in order to load the data. We can work with the file system programmatically through R. here: Use here::here() to create paths relative to the project root directory. portable independent of the where code is evaluated or saved. Let’s start by creating a path to the downloaded data directory using here. raw_data_path &lt;- here::here(&quot;data-raw&quot;, &quot;wood-survey-data-master&quot;) raw_data_path ## [1] &quot;/Users/Anna/Documents/workflows/workshops/books/rrresearchACCE20/data-raw/wood-survey-data-master&quot; &quot;/Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master&quot; We can use raw_data_path as our basis for specifying paths to files within it. There’s a number of ways we can do this in R but I wanted to introduce you to package fs. It has a nice interface and extensive functionality. fs::path(raw_data_path, &quot;individual&quot;) ## /Users/Anna/Documents/workflows/workshops/books/rrresearchACCE20/data-raw/wood-survey-data-master/individual /Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual Let’s now use function dir_ls to get a character vector of paths to all the individual files in directory individual. individual_paths &lt;- fs::dir_ls(fs::path(raw_data_path, &quot;individual&quot;)) head(individual_paths) ## /Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual/NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2015-08.basic.20190806T172340Z.csv ## /Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual/NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2015-09.basic.20190806T144119Z.csv ## /Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual/NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2016-08.basic.20190806T143255Z.csv ## /Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual/NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2016-09.basic.20190806T143433Z.csv ## /Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual/NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2016-10.basic.20190806T144133Z.csv ## /Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual/NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2017-07.basic.20190806T144111Z.csv We can check how many files we’ve got: length(individual_paths) ## [1] 67 We can now use this vector of paths to read in files. Let’s read the first file in and check it out. We use function read_csv() from readr package which reads comma delimited files into tibbles. indiv_df &lt;- readr::read_csv(individual_paths[1]) ## Parsed with column specification: ## cols( ## uid = col_character(), ## namedLocation = col_character(), ## date = col_date(format = &quot;&quot;), ## eventID = col_character(), ## domainID = col_character(), ## siteID = col_character(), ## plotID = col_character(), ## individualID = col_character(), ## growthForm = col_character(), ## stemDiameter = col_double(), ## measurementHeight = col_double(), ## height = col_double() ## ) indiv_df ## # A tibble: 369 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 359 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; Run ?read_delim for more details on reading in tabular data. Basic checks Let’s perform some of the basic checks we learnt before we proceed. View(indiv_df) names(indiv_df) ## [1] &quot;uid&quot; &quot;namedLocation&quot; &quot;date&quot; ## [4] &quot;eventID&quot; &quot;domainID&quot; &quot;siteID&quot; ## [7] &quot;plotID&quot; &quot;individualID&quot; &quot;growthForm&quot; ## [10] &quot;stemDiameter&quot; &quot;measurementHeight&quot; &quot;height&quot; ## tibble [369 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ uid : chr [1:369] &quot;68dc7adf-48e2-4f7a-9272-9a468fde6d55&quot; &quot;a8951ab9-4462-48dd-ab9e-7b89e24f2e03&quot; &quot;eb348eaf-3969-46a4-ac3b-523c3548efeb&quot; &quot;2a4478ef-5970-40b6-b696-d1167cbe42ac&quot; ... ## $ namedLocation : chr [1:369] &quot;BART_037.basePlot.vst&quot; &quot;BART_044.basePlot.vst&quot; &quot;BART_044.basePlot.vst&quot; &quot;BART_044.basePlot.vst&quot; ... ## $ date : Date[1:369], format: &quot;2015-08-26&quot; &quot;2015-08-26&quot; ... ## $ eventID : chr [1:369] &quot;vst_BART_2015&quot; &quot;vst_BART_2015&quot; &quot;vst_BART_2015&quot; &quot;vst_BART_2015&quot; ... ## $ domainID : chr [1:369] &quot;D01&quot; &quot;D01&quot; &quot;D01&quot; &quot;D01&quot; ... ## $ siteID : chr [1:369] &quot;BART&quot; &quot;BART&quot; &quot;BART&quot; &quot;BART&quot; ... ## $ plotID : chr [1:369] &quot;BART_037&quot; &quot;BART_044&quot; &quot;BART_044&quot; &quot;BART_044&quot; ... ## $ individualID : chr [1:369] &quot;NEON.PLA.D01.BART.05279&quot; &quot;NEON.PLA.D01.BART.05419&quot; &quot;NEON.PLA.D01.BART.05092&quot; &quot;NEON.PLA.D01.BART.05443&quot; ... ## $ growthForm : chr [1:369] &quot;single bole tree&quot; &quot;single bole tree&quot; &quot;single bole tree&quot; &quot;single bole tree&quot; ... ## $ stemDiameter : num [1:369] 13.7 12.3 12.1 29.2 12.1 23.4 39.5 10 10.6 24.6 ... ## $ measurementHeight: num [1:369] 130 130 130 130 130 130 130 130 130 130 ... ## $ height : num [1:369] 9.8 7.7 15.2 16.7 10.6 18.4 19 5.7 8.7 19.2 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. uid = col_character(), ## .. namedLocation = col_character(), ## .. date = col_date(format = &quot;&quot;), ## .. eventID = col_character(), ## .. domainID = col_character(), ## .. siteID = col_character(), ## .. plotID = col_character(), ## .. individualID = col_character(), ## .. growthForm = col_character(), ## .. stemDiameter = col_double(), ## .. measurementHeight = col_double(), ## .. height = col_double() ## .. ) ## uid namedLocation date eventID ## Length:369 Length:369 Min. :2015-08-26 Length:369 ## Class :character Class :character 1st Qu.:2015-08-27 Class :character ## Mode :character Mode :character Median :2015-08-27 Mode :character ## Mean :2015-08-27 ## 3rd Qu.:2015-08-31 ## Max. :2015-08-31 ## domainID siteID plotID individualID ## Length:369 Length:369 Length:369 Length:369 ## Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character ## ## ## ## growthForm stemDiameter measurementHeight height ## Length:369 Min. : 6.50 Min. :115 Min. : 1.80 ## Class :character 1st Qu.:13.90 1st Qu.:130 1st Qu.:10.50 ## Mode :character Median :20.20 Median :130 Median :14.40 ## Mean :23.33 Mean :130 Mean :13.99 ## 3rd Qu.:30.20 3rd Qu.:130 3rd Qu.:17.30 ## Max. :69.90 Max. :140 Max. :30.20 Everything looks good. So let’s move onto the next step of reading in all the files and combining them together. To do this, we’ll examine the principles of Iteration. "],
["process.html", "(PART) Data Munging", " (PART) Data Munging "],
["data-munging-iteration.html", "Data Munging: Iteration Iterating using loops Functional programming Writing out our tibble to disk", " Data Munging: Iteration Let’s say we want to repeat a process multiple times, iterating over a number of inputs. In this case we want to load every file in /data-raw/wood-survey-data-master/individual/. We have a few options for how to approach this problem. In R there are two paradigms for iteration: imperative iterations: (for and while loops) great place to start because they make iteration very explicit. quite verbose, and require quite a bit of bookkeeping code that is duplicated for every for loop. functional programming: using functions to iterate over other functions. focus is on the operation being performed rather than the bookkeeping. can be more elegant and succinct. Iterating using loops Simple loop Here’s an example of a simple loop. During each iteration, it prints a message to the console, reporting the value of i. for(i in 1:10){ print(paste0(&quot;i is &quot;, i)) } ## [1] &quot;i is 1&quot; ## [1] &quot;i is 2&quot; ## [1] &quot;i is 3&quot; ## [1] &quot;i is 4&quot; ## [1] &quot;i is 5&quot; ## [1] &quot;i is 6&quot; ## [1] &quot;i is 7&quot; ## [1] &quot;i is 8&quot; ## [1] &quot;i is 9&quot; ## [1] &quot;i is 10&quot; The loop iterates over the vector of values supplied in 1:10, sequentially assigning a new value to variable i each iteration. i is therefore the varying input and everything else in the code stays the same during each iteration. Loops in practice Reading in multiple files Let’s now apply a loop to read in all 67 files at once. We have the file paths in our individual_paths vector. This is the input we want to iterate over. We can use a for loop to supply each path as the file argument in readr::read_csv(). Storing loop outputs The previous loop we saw didn’t generate any new objects, it just printed output to the console. We, however, need to store the output of each iteration (the tibble we’ve just read in). It’s important for efficiency to allocate sufficient space for the output before starting a for loop. Growing the for loop at each iteration, using c() for example, will be very slow. Let’s create an output vector to store the tibbles containing the read in data. We want it to be a list because we’ll be storing heterogeneous objects (tibbles) in each element. indiv_df_list &lt;- vector(&quot;list&quot;, length(individual_paths)) head(indiv_df_list) ## [[1]] ## NULL ## ## [[2]] ## NULL ## ## [[3]] ## NULL ## ## [[4]] ## NULL ## ## [[5]] ## NULL ## ## [[6]] ## NULL We’ve used the length() of the input to specify the size of our output list so each path gets an output element. Looping over indices Next, we need a sequence of indices as long as the input vector (individual_paths). We can use seq_along() to create our index vector: seq_along(individual_paths) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ## [51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 Now we’re ready to write our for loop. for(i in seq_along(individual_paths)){ indiv_df_list[[i]] &lt;- readr::read_csv(individual_paths[[i]]) } At each step of the iteration, the file specified in the ith element of individual_paths is read in and assigned to th ith element of our output list. We can extract individual tibbles using [[ sub-setting to inspect: indiv_df_list[[1]] ## # A tibble: 369 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 359 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; indiv_df_list[[2]] ## # A tibble: 673 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 fb75… BART_036.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 30a7… BART_046.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 789d… BART_072.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 0e4f… BART_072.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 7397… BART_036.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 cb0e… BART_036.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 5fc5… BART_072.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 5d15… BART_046.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 d27a… BART_036.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 d5f9… BART_036.bas… 2015-09-01 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 663 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; We can also inspect the contents of our output list interactively using View() Looping over objects We can also loop over objects instead of indices. indiv_df_list &lt;- vector(&quot;list&quot;, length(individual_paths)) names(indiv_df_list) &lt;- basename(individual_paths) for(path in individual_paths){ indiv_df_list[[basename(path)]] &lt;- readr::read_csv(path) } In this case, we supply the paths themselves as the input to our loop and these are passed as-is to read_csv(). This time we don’t have our element indices to index the elements of the output list each tibble should be stored in. To get around this we assign names to each element and index the output list by name. I’ve chosen to use the basename (actual file name) of each path as a name, which I can get through basename(). individual_paths[1] basename(individual_paths[1]) ## ~/Desktop/wood-survey/data-raw/wood-survey-data-master/individual ## [1] &quot;individual&quot; Collapsing our output list into a single tibble. Now we’ve got our list of tibbles, we want to collapse or “reduce” our output list into a single tibble. There are a number of ways to do this in R. Base R One first approach we might think of is to use base function rbind(). This takes any number of tibbles as arguments and binds them all together. rbind(indiv_df_list) %&gt;% head() ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2015-08.basic.20190806T172340Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2015-09.basic.20190806T144119Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2016-08.basic.20190806T143255Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2016-09.basic.20190806T143433Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2016-10.basic.20190806T144133Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2017-07.basic.20190806T144111Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2017-08.basic.20190806T143426Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2017-09.basic.20190806T143740Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2018-08.basic.20190806T143026Z.csv ## indiv_df_list List,12 ## NEON.D01.BART.DP1.10098.001.vst_apparentindividual.2018-09.basic.20190806T144743Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2015-08.basic.20190806T155155Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2015-09.basic.20190806T155228Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2015-10.basic.20190806T160029Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2015-11.basic.20190806T155340Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2016-07.basic.20190806T154424Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2016-08.basic.20190806T155619Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2016-09.basic.20190806T155751Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2016-10.basic.20190806T154902Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2017-07.basic.20190806T161731Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2017-08.basic.20190806T155239Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2017-09.basic.20190806T154054Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2017-10.basic.20190806T154917Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2018-09.basic.20190806T154756Z.csv ## indiv_df_list List,12 ## NEON.D01.HARV.DP1.10098.001.vst_apparentindividual.2018-10.basic.20190904T080421Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2015-09.basic.20190806T180623Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2015-10.basic.20190806T180501Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2016-09.basic.20190806T180452Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2016-11.basic.20190806T162810Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2017-09.basic.20190806T180226Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2017-10.basic.20190806T162804Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2018-09.basic.20190806T162758Z.csv ## indiv_df_list List,12 ## NEON.D02.BLAN.DP1.10098.001.vst_apparentindividual.2018-11.basic.20190930T153245Z.csv ## indiv_df_list List,12 ## NEON.D03.DSNY.DP1.10098.001.vst_apparentindividual.2018-01.basic.20190806T170456Z.csv ## indiv_df_list List,12 ## NEON.D03.DSNY.DP1.10098.001.vst_apparentindividual.2018-05.basic.20190806T165614Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2015-08.basic.20190806T155333Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-02.basic.20190806T151351Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-03.basic.20190806T151416Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-04.basic.20190806T151437Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-05.basic.20190806T154733Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-06.basic.20190806T155301Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-07.basic.20190806T155324Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-08.basic.20190806T153300Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-09.basic.20190806T151857Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-10.basic.20190806T154351Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2016-11.basic.20190806T152215Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2017-03.basic.20190806T152514Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2017-04.basic.20190806T154915Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2017-12.basic.20190806T164409Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2018-01.basic.20190806T150606Z.csv ## indiv_df_list List,12 ## NEON.D04.GUAN.DP1.10098.001.vst_apparentindividual.2018-02.basic.20190806T150635Z.csv ## indiv_df_list List,12 ## NEON.D07.GRSM.DP1.10098.001.vst_apparentindividual.2015-05.basic.20190806T151458Z.csv ## indiv_df_list List,12 ## NEON.D07.GRSM.DP1.10098.001.vst_apparentindividual.2015-06.basic.20190806T151516Z.csv ## indiv_df_list List,12 ## NEON.D07.GRSM.DP1.10098.001.vst_apparentindividual.2016-10.basic.20190806T154811Z.csv ## indiv_df_list List,12 ## NEON.D07.GRSM.DP1.10098.001.vst_apparentindividual.2016-11.basic.20190806T154932Z.csv ## indiv_df_list List,12 ## NEON.D07.GRSM.DP1.10098.001.vst_apparentindividual.2017-10.basic.20190806T155315Z.csv ## indiv_df_list List,12 ## NEON.D07.GRSM.DP1.10098.001.vst_apparentindividual.2017-11.basic.20190806T164155Z.csv ## indiv_df_list List,12 ## NEON.D07.GRSM.DP1.10098.001.vst_apparentindividual.2018-11.basic.20190930T154643Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2015-06.basic.20190806T173627Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2015-07.basic.20190806T165116Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2015-09.basic.20190806T160924Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2016-09.basic.20190806T161107Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2016-10.basic.20190806T155600Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2017-10.basic.20190806T161504Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2017-11.basic.20190806T165044Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2018-10.basic.20190904T074322Z.csv ## indiv_df_list List,12 ## NEON.D08.DELA.DP1.10098.001.vst_apparentindividual.2018-11.basic.20190930T162311Z.csv ## indiv_df_list List,12 ## NEON.D09.DCFS.DP1.10098.001.vst_apparentindividual.2015-09.basic.20190806T161704Z.csv ## indiv_df_list List,12 Hmm, that doesn’t seem to have done what we want. That’s because rbind expects multiple tibbles as inputs and we’re giving it a single list. We somehow want to extract the contents of each element of indiv_df_list and pass them all to rbind. For this we can use do.call.do.call takes a function or the name of a function we want to execute as it’s first argument, what. The second argument of do.call, args is a list of arguments we want to pass to the function specified in what. When do.call is executed, it extracts the elements of args and passes them as arguments to what. do.call(what = &quot;rbind&quot;, args = indiv_df_list) ## # A tibble: 21,388 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## * &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; Success! Tidyverse There are also ways to do this using the tidyverse. purrr::reduce reduce from package purrr combines the elements of a vector or list into a single object according to the function supplied to .f. purrr::reduce(indiv_df_list, .f = rbind) ## # A tibble: 21,388 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; dplyr::bind_rows bind_rows offers a shortcut to reducing a list of tibbles. dplyr::bind_rows(indiv_df_list) ## # A tibble: 21,388 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; Functional programming Loops are an important basic concept in programming. However another approach available in R is functional programming which vectorises a function or pipe of functions over given input(s). We’ve actually just been using functional programming with do.call and reduce. This idea of passing a function to another function is one of the behaviours that makes R a functional programming language and is extremely powerful. It allows us to: use functions rather than for loops to perform iteration over other functions. wrap the code we want to iterate over in custom functions. This iin turn allows us to replace many for loops with code that is both more succinct and easier to read. In base R there is a family of apply functions (lapply, vapply, sapply, apply, mapply). These are handy to know if want to write workflows or software that are low on dependencies. However, I prefer using the functions in tidyverse package purrr. Iterating using purrr In the tidyverse such functionality is provided by package purrr, which provides a complete and consistent set of tools for working with functions and vectors of inputs. The first thing we might try is to replace our for loop with a function. map The basic purrr function is map() and it allows us to pass the elements of an input vector or list to a single argument of a function we want to repeat. It also has a handy shortcut for specifying the argument to pass the input object to. indiv_df_list &lt;- purrr::map(individual_paths, ~readr::read_csv(file = .x)) The first argument to map is the input vector of paths we want to iterate over. The next argument is a formula specifying the function we want to repeat as well as which argument the input is passed to. Here we’re saying that we want to repeatedly run read_csv and we indicate the argument we want the input passed to (file) by .x. Note as well the ~ notation before the function definition which is shorthand for .f =. map_df Just like our loop, map returns an output list. class(indiv_df_list) ## [1] &quot;list&quot; We would therefore need to combine them together in another step. However, one of the great things about purrr functions is that you can specify what you expect the output of the mapped function to be. THere are functions that take advantage of that knowledge and bind or format the outputs appropriately. Because we know the output of read_csv() is a tibble, we can use map_df() instead of map(). individual &lt;- purrr::map_df(individual_paths, ~readr::read_csv(.x)) individual ## # A tibble: 21,388 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; Success! We now have all our data in a single tibble is just two concise lines of code!! 🎉 👏 Some tips on efficiency While the above code is elegant, it might not be the most efficient. read_csv calls readr function type_convert() to determine the data type for each column when it reads a file in, which is relatively expensive. The elegant code above mean that type_convert() is for every file that is loaded, ie 67 times. A more efficent way of implementing this to set all columns as character on-read and then run type_convert ourselves, only once, and only after our data have been combined into a single tibble. We can set all columns to character by default by providing column formating function readr::cols(.default = &quot;c&quot;)) as the read_csv col_types argument. individual &lt;- purrr::map_df(individual_paths, ~readr::read_csv(.x, col_types = readr::cols(.default = &quot;c&quot;))) %&gt;% readr::type_convert() individual ## # A tibble: 21,388 x 12 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 4 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt; This might come in handy if you are dealing with a huge number of data files. Other packages to be aware of, especially if you are dealing with very large tables, are data.table and vroom. Learn more about perfomance and efficency in general. simple benchmark microbenchmark::microbenchmark({ # tidyverse purrr::map_df(individual_paths, ~readr::read_csv(.x))}, # tidyverse + read in as character {purrr::map_df(individual_paths, ~readr::read_csv(.x, col_types = readr::cols(.default = &quot;c&quot;))) %&gt;% readr::type_convert()}, # vroom package {vroom::vroom(individual_paths)}, # data.table {lapply(individual_paths, data.table::fread, sep=&quot;,&quot;) %&gt;% do.call(&quot;rbind&quot;, .)}, # purrr + data.table {purrr::map_df(individual_paths, data.table::fread, sep=&quot;,&quot;)}, times = 20) min lq mean median uq max neval 372.77828 389.98348 416.70189 395.01877 437.90033 512.19128 20 150.52621 164.60759 190.92799 175.99858 192.44910 322.73216 20 265.06628 272.09506 307.39295 285.53955 320.84952 518.55182 20 50.09148 53.22408 72.28593 58.26753 63.00565 182.50278 20 57.48761 58.76176 63.39054 63.31130 66.08371 75.92438 20 Writing out our tibble to disk Remember the other two files included in our raw data, vst_mappingandtagging.csv, and vst_perplotperyear.csv? Well the truth is they also came in multiple files which I put together in pretty much the same way as you just did! So for posterity, let’s save this file out too. This isn’t our finished analytic data set, we still have some processing to do. So let’s just save it at raw_data_path, along with the other files. To write out a csv file we use readr::write_csv() individual %&gt;% readr::write_csv(file.path(raw_data_path, &quot;vst_individual.csv&quot;)) Learn more about iteration and the family of purrr functions in the iteration chapter in R for data science "],
["data-munging-combining-tables.html", "Data munging: combining tables Joining tables with dplyr", " Data munging: combining tables Let’s say we want to geolocate every individual plant in out data. Currently, only the plot is geolocated, the data being contained in vst_perplotperyear.csv columns decimalLatitude and decimalLongitude. The location of each individual stem is defined in vst_mappingandtagging.csv. A number of variables are involved, including pointID which identifies a point on a 10m cell grid centered around decimalLatitude and decimalLongitude, and stemDistance and stemAzimuth which defines the location of a stem, relative to the location of pointID. is detailed in methods/NEON_vegStructure_userGuide_vA.pdf but we will briefly describe here. knitr::include_graphics(&quot;assets/NEON_point_grid.png&quot;, error = FALSE) library(magrittr) library(dplyr) raw_data_path &lt;- here::here(&quot;data-raw&quot;, &quot;wood-survey-data-master&quot;) individual &lt;- readr::read_csv(file.path(raw_data_path, &quot;vst_individual.csv&quot;), guess_max = 8000) ## Parsed with column specification: ## cols( ## uid = col_character(), ## namedLocation = col_character(), ## date = col_date(format = &quot;&quot;), ## eventID = col_character(), ## domainID = col_character(), ## siteID = col_character(), ## plotID = col_character(), ## individualID = col_character(), ## growthForm = col_character(), ## stemDiameter = col_double(), ## measurementHeight = col_double(), ## height = col_double() ## ) Joining tables with dplyr # &quot;Mutating&quot; joins combine variables from the LHS and RHS band_members %&gt;% inner_join(band_instruments) ## Joining, by = &quot;name&quot; ## # A tibble: 2 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Beatles guitar ## 2 Paul Beatles bass band_members %&gt;% left_join(band_instruments) ## Joining, by = &quot;name&quot; ## # A tibble: 3 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; ## 2 John Beatles guitar ## 3 Paul Beatles bass band_members %&gt;% right_join(band_instruments) ## Joining, by = &quot;name&quot; ## # A tibble: 3 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Beatles guitar ## 2 Paul Beatles bass ## 3 Keith &lt;NA&gt; guitar band_members %&gt;% full_join(band_instruments) ## Joining, by = &quot;name&quot; ## # A tibble: 4 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; ## 2 John Beatles guitar ## 3 Paul Beatles bass ## 4 Keith &lt;NA&gt; guitar Application Merge vst_mappingandtagging.csv First let’s read in both tables we need, vst_perplotperyear.csv and vst_mappingandtagging.csv. maptag &lt;- readr::read_csv(fs::path(raw_data_path, &quot;vst_mappingandtagging.csv&quot;)) First we’ll merge data from maptag. This data set contains taxonomic and within-plot location metadata on individuals collected during mapping and tagging. There is one row per individual in the data set. names(maptag) ## [1] &quot;uid&quot; &quot;namedLocation&quot; &quot;date&quot; &quot;eventID&quot; ## [5] &quot;domainID&quot; &quot;siteID&quot; &quot;plotID&quot; &quot;pointID&quot; ## [9] &quot;stemDistance&quot; &quot;stemAzimuth&quot; &quot;individualID&quot; &quot;taxonID&quot; ## [13] &quot;scientificName&quot; &quot;taxonRank&quot; #dplyr::select(maptag, individualID, taxonID:taxonRank, pointID:stemAzimuth) individual %&gt;% dplyr::left_join(maptag) ## Joining, by = c(&quot;uid&quot;, &quot;namedLocation&quot;, &quot;date&quot;, &quot;eventID&quot;, &quot;domainID&quot;, &quot;siteID&quot;, &quot;plotID&quot;, &quot;individualID&quot;) ## # A tibble: 21,388 x 18 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 10 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt;, pointID &lt;dbl&gt;, ## # stemDistance &lt;dbl&gt;, stemAzimuth &lt;dbl&gt;, taxonID &lt;chr&gt;, scientificName &lt;chr&gt;, ## # taxonRank &lt;chr&gt; Great we have our merge! Looks successful right? How do we really know nothing has gone wrong. Remember, to successfully merge the tables, the data withing the columns the tables are being merged need to have corresponding values across all columns to be linked successfully so while the code ran, it may well not have found any matching rows in maptag to merge into individual. To check whether things have worked, we need to at least start with inspecting for the objects of interest. When working interactively and testing out pipes, you can pipe objects into View() for easier inspection. If you provide a character string as an argument, it is used as a name for the data view tab it launches individual %&gt;% dplyr::left_join(maptag) %&gt;% View(&quot;default&quot;) Clearly this has not worked! We need to start digging into why but we don’t want to have to keep manually checking whether it worked or not. Enter DEFENSIVE PROGRAMMING. Defensive programming in scripts testthat assertr checkmate individual %&gt;% dplyr::left_join(maptag) %&gt;% assertr::assert(assertr::not_na, stemAzimuth) ## Joining, by = c(&quot;uid&quot;, &quot;namedLocation&quot;, &quot;date&quot;, &quot;eventID&quot;, &quot;domainID&quot;, &quot;siteID&quot;, &quot;plotID&quot;, &quot;individualID&quot;) ## Column &#39;stemAzimuth&#39; violates assertion &#39;not_na&#39; 21388 times ## verb redux_fn predicate column index value ## 1 assert NA not_na stemAzimuth 1 NA ## 2 assert NA not_na stemAzimuth 2 NA ## 3 assert NA not_na stemAzimuth 3 NA ## 4 assert NA not_na stemAzimuth 4 NA ## 5 assert NA not_na stemAzimuth 5 NA ## [omitted 21383 rows] ## Error: assertr stopped execution Handling clashes: I’ve shown the most minimal implementation in which dplyr does a lot of the guessing for us Be specific about which variables you want to: Including them means they are combined into one column. If there are variable of the same name in both tables and they are not included in by, they will be kept in the new table and each suffixed with df &lt;- individual %&gt;% dplyr::left_join(maptag, by = c(&quot;namedLocation&quot;, &quot;date&quot;, &quot;eventID&quot;, &quot;domainID&quot;, &quot;siteID&quot;, &quot;plotID&quot;, &quot;individualID&quot;)) individual %&gt;% dplyr::left_join(maptag, by = c(&quot;namedLocation&quot;, &quot;domainID&quot;, &quot;siteID&quot;, &quot;plotID&quot;, &quot;individualID&quot;)) %&gt;% View() individual %&gt;% dplyr::left_join(dplyr::select(maptag, individualID, taxonID:taxonRank, pointID:stemAzimuth)) ## Joining, by = &quot;individualID&quot; ## # A tibble: 21,388 x 18 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 10 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt;, taxonID &lt;chr&gt;, ## # scientificName &lt;chr&gt;, taxonRank &lt;chr&gt;, pointID &lt;dbl&gt;, stemDistance &lt;dbl&gt;, ## # stemAzimuth &lt;dbl&gt; nrow_indiv &lt;- nrow(individual) individual %&gt;% dplyr::left_join(dplyr::select(maptag, -uid, -date)) ## Joining, by = c(&quot;namedLocation&quot;, &quot;eventID&quot;, &quot;domainID&quot;, &quot;siteID&quot;, &quot;plotID&quot;, &quot;individualID&quot;) ## # A tibble: 21,388 x 18 ## uid namedLocation date eventID domainID siteID plotID individualID ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 68dc… BART_037.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 2 a895… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 3 eb34… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 4 2a44… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 5 e485… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 6 280c… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 7 0e50… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 8 4918… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 9 ef16… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## 10 f099… BART_044.bas… 2015-08-26 vst_BA… D01 BART BART_… NEON.PLA.D0… ## # … with 21,378 more rows, and 10 more variables: growthForm &lt;chr&gt;, ## # stemDiameter &lt;dbl&gt;, measurementHeight &lt;dbl&gt;, height &lt;dbl&gt;, pointID &lt;dbl&gt;, ## # stemDistance &lt;dbl&gt;, stemAzimuth &lt;dbl&gt;, taxonID &lt;chr&gt;, scientificName &lt;chr&gt;, ## # taxonRank &lt;chr&gt; Let’s test to make sure we have not inadvertently added data through rogue duplicate data. individual %&gt;% dplyr::left_join(maptag) %&gt;% assertr::verify(nrow(.) == nrow_indiv) %&gt;% assertr::assert(assertr::not_na, stemAzimuth) ## Joining, by = c(&quot;uid&quot;, &quot;namedLocation&quot;, &quot;date&quot;, &quot;eventID&quot;, &quot;domainID&quot;, &quot;siteID&quot;, &quot;plotID&quot;, &quot;individualID&quot;) ## Column &#39;stemAzimuth&#39; violates assertion &#39;not_na&#39; 21388 times ## verb redux_fn predicate column index value ## 1 assert NA not_na stemAzimuth 1 NA ## 2 assert NA not_na stemAzimuth 2 NA ## 3 assert NA not_na stemAzimuth 3 NA ## 4 assert NA not_na stemAzimuth 4 NA ## 5 assert NA not_na stemAzimuth 5 NA ## [omitted 21383 rows] ## Error: assertr stopped execution The data passes through the pipe after successfully passing our test. Now let’s say we also want to make sure our data was correctly matched and merged. We can do this by checking that there are there are no NAs in some key columns of interest: checkmate::check_true(nrow(individual) == nrow_indiv) ## [1] TRUE Merge vst_mappingandtagging.csv First let’s read in both tables we need, vst_perplotperyear.csv and vst_mappingandtagging.csv. perplot &lt;- readr::read_csv(fs::path(raw_data_path, &quot;vst_perplotperyear.csv&quot;)) maptag &lt;- readr::read_csv(fs::path(raw_data_path, &quot;vst_mappingandtagging.csv&quot;)) individual %&lt;&gt;% dplyr::left_join(dplyr::select(perplot, siteID:eventID)) ## Joining, by = c(&quot;eventID&quot;, &quot;siteID&quot;, &quot;plotID&quot;) "],
["data-munging-functions.html", "Data Munging: functions", " Data Munging: functions Let’s say we want to geolocate every individual plant in out data. Currently, only the plot is geolocated, the data being contained in vst_perplotperyear.csv columns decimalLatitude and decimalLongitude. The location of each individual is defined in vst_mappingandtagging.csv which is detailed in methods/NEON_vegStructure_userGuide_vA.pdf but we will briefly describe here. Spatal Sampling Design At sites with qualifying woody and/or non-herbaceous vegetaton, stem mapping actvites and the collecton of vegetaton structure data take place in up to n=20 randomly selected, spatally-balanced Distributed Plots, te axact number and size of the plot varying according to plot type. An offset mapping technique is used to determine the within-plot locaton of mapped individuals relative to permanent plot markers (pointIDs) for which high-resoluton GPS data are collected (Figure 3). For additonal details on the sampling design and associated protocol, see TOS Protocol and Procedure: Measurement of Vegetation Structure. knitr::include_graphics(&quot;assets/NEON_point_grid.png&quot;, error = FALSE) Making new variables "],
["metadata-1.html", "Metadata", " Metadata View Slides "],
["analysing.html", "(PART) Part III: Analysing and presenting analyses", " (PART) Part III: Analysing and presenting analyses "],
["literate-programming-in-rmarkdown.html", "Literate programming in rmarkdown Why is this important in science: Calls for open science tl;dr Rmarkdown overview elements of R markdown markdown {.md} code {r, python, SQL, … } outputs Publish to the web for free! Applications in research 💻 Exercise Part 1 🚦 YAML header define outputs define a floating table of contents choose a theme choose code highlights 💻 Exercise Part 2 🚦 Markdown basics text headers unordered lists ordered lists quotes code images basic tables in markdown links mathematical expressions 💻 Exercise: Part 3 🚦 Chunks &amp; Inline R code inserting new chunks chunk uses chunk notation chunk options uses 💻 Exercise Part 4 🚦 Displaying data 💻 Exercise Part 5 🚦 plots 💻 Exercise Part 6a Exercise Part 6b 🚦 Advanced .Rmd reading chunks of code Extracting code from an .Rmd 💻 Exercise: Part 7* purl your document 🚦 html in rmarkdown Parting words Getting help with markdown Resources Solutions: My example", " Literate programming in rmarkdown ## ── Attaching packages ────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.0 ✓ purrr 0.3.3 ## ✓ tibble 3.0.0 ✓ stringr 1.4.0 ## ✓ tidyr 1.0.2 ✓ forcats 0.5.0 ## ✓ readr 1.3.1 ## ── Conflicts ───────────────────────── tidyverse_conflicts() ── ## x magrittr::equals() masks testthat::equals() ## x tidyr::extract() masks magrittr::extract() ## x dplyr::filter() masks stats::filter() ## x magrittr::is_less_than() masks testthat::is_less_than() ## x purrr::is_null() masks testthat::is_null() ## x dplyr::lag() masks stats::lag() ## x tidyr::matches() masks dplyr::matches(), testthat::matches() ## x magrittr::not() masks testthat::not() ## x purrr::set_names() masks magrittr::set_names() Programming paradigm first introduced by Donald E. Knuth. Treat program as a literature understandable to human beings move away from writing programs in the manner and order imposed by the computer focus instead on the logic and flow of human thought and understanding single document to integrate data analysis (executable code) with textual documentation, linking data, code, and text Why is this important in science: Calls for reproducibility Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible. Fully scripted analyses pipelines from raw data to published tables and figures Publication of code and data Calls for open science … highlight problems with users jumping straight into software implementations of methods (e.g. in r) that may lack documentation on biases and assumptions that are mentioned in the original papers. To help solve these problems, we make a number of suggestions including providing blog posts or videos to explain new methods in less technical terms, encouraging reproducibility and code sharing, making wiki-style pages summarising the literature on popular methods, more careful consideration and testing of whether a method is appropriate for a given question/data set, increased collaboration, and a shift from publishing purely novel methods to publishing improvements to existing methods and ways of detecting biases or testing model fit. Many of these points are applicable across methods in ecology and evolution, not just phylogenetic comparative methods. tl;dr Modern open source technologies have given us great power With great power comes great responsibility You can share some of that burden by using these tools to open your work up to feedback and contribution by others. The more eyes the better. Use them to provide and context around your work. Help more humans understand Literate programming in R rmarkdown (.Rmd) integrates: – a documentantion language (.md) – a programming language (R) Combine tools, processes and outputs into interactive evidence streams that are easily shareable, particularly through the web. Rmarkdown overview Features Rstudio features fly through What is R Markdown? from RStudio, Inc. on Vimeo. The researchers perspective a reproducible workflow in action elements of R markdown markdown {.md} stripped down html. User can focus on communicating &amp; disseminating intended to be as easy-to-read and easy-to-write as possible. most powerful as a format for writing to the web. syntax is very small, corresponding only to a very small subset of HTML tags. clean and legible across platforms (even mobile) and outputs. formatting handled automatically html markup language also handled. code {r, python, SQL, … } Code chunks defined through special notation. Executed in sequence. Exceution of individual chunks controllable Analysis self-contained and reproducible Run in a fresh R session every time document is knit. A number of Language Engines are supported by knitr R (default) Python SQL Bash Rcpp Stan JavaScript CSS Can read appropriately annotated .R scripts in and call them within an .Rmd outputs Knit together through package knitr to Many great packages and applications build on rmarkdown. All this makes it incredibly versatile. Check out the gallery. Superpower: Simple interface to powerful modern web technologies and libraries Publish to the web for free! RPubs: Publish rendered rmarkdown documents on the web with the click of a button http://rpubs.com/ GitHub: Host your site through gh-pages on GitHub. Can host entire websites, like this course material https://github.com/ Applications in research Rmd documents Can be useful for a number of research related materials Vignettes: long form documentation. Analyses Documentation (code &amp; data) Supplementary materials Reports Papers Useful features: - bibliographies and citations 💻 Exercise Part 1 Throughout this workshop, we’ll be working with the gapminder dataset to produce a reproducible Rmarkdown vignette of our work. We’ll also be working in a project and setting our analysis report up to be shared online! install the packages we’ll need install.packages(c(&quot;skimr&quot;, &quot;ggplot2&quot;, &quot;dplyr&quot;, &quot;plotly&quot;, &quot;DT&quot;, &quot;tibble&quot;)) Create new project gapminder-analysis File &gt; New Project… &gt; New Directory &gt; New Project &gt; gapminder-analysis Create your first .Rmd! File &gt; New File &gt; RMarkdown… &gt; Document Save as index.Rmd Before knitting, the document needs to be saved. Give it a useful name, e.g. index.Rmd Render it Render the document by clicking on the knit button. You can also render .Rmd documents to html using rmarkdown function render() rmarkdown::render(input = &quot;index.Rmd&quot;) Publish your .Rmd Register an account on RPubs Publish your rendered document (don’t worry, you can delete or overwrite it later) open the cheatsheet 🚦 YAML header https://bookdown.org/yihui/rmarkdown/markdown-syntax.html The yaml header contains metadata about the document, most importantly the output. Different seetings can be set within different outputs. Here we’ll be focusing on on the html_document output. It is contained between these separators at the top of the file. Markdown was originally designed for HTML output, so it may not be surprising that the HTML format has the richest features among all output formats. define outputs To create an HTML document from R Markdown, you specify the html_document output format in the YAML metadata of your document: basic html_document title: &quot;Untitled&quot; author: &quot;Anna Krystalli&quot; date: &quot;3/23/2018&quot; output: html_document define a floating table of contents You can add a table of contents (TOC) using the toc option and specify a floating toc using the toc_float option. For example: --- title: &quot;Untitled&quot; author: &quot;Anna Krystalli&quot; date: &quot;3/23/2018&quot; output: html_document: toc: true toc_float: true --- choose a theme There are several options that control the appearance of HTML documents: theme specifies the Bootstrap theme to use for the page (themes are drawn from the Bootswatch theme library). Valid themes include default, cerulean, journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, and yeti. --- title: &quot;Untitled&quot; author: &quot;Anna Krystalli&quot; date: &quot;3/23/2018&quot; output: html_document: toc: true toc_float: true theme: cosmo --- choose code highlights highlight specifies the syntax highlighting style. Supported styles include default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, and textmate. --- title: &quot;Untitled&quot; author: &quot;Anna Krystalli&quot; date: &quot;3/23/2018&quot; output: html_document: toc: true toc_float: true theme: cosmo highlight: zenburn --- 💻 Exercise Part 2 Clear everything BELOW THE YAML header. You should be left with just this: --- title: &quot;Gapminder Analysis&quot; author: &quot;Anna Krystalli&quot; date: &quot;3/23/2018&quot; output: html_document --- add a floating table of contents set a theme of your choice (see avalable themes here and the associated bootstrap styles here) 🚦 Markdown basics The text in an R Markdown document is written with the Markdown syntax. Precisely speaking, it is Pandoc’s Markdown. text normal text normal text *italic text* italic text **bold text** bold text ***bold italic text*** bold italic text superscript^2^ superscript2 ~~strikethrough~~ strikethrough headers rmarkdown # Header 1 ## Header 2 ### Header 3 #### Header 4 ##### Header 5 ###### Header 6 rendered html unordered lists rmarkdown - first item in the list - second item in list - third item in list rendered html first item in the list second item in list third item in list ordered lists rmarkdown 1. first item in the list 1. second item in list 1. third item in list rendered html first item in the list second item in list third item in list quotes rmarkdown &gt; this text will be quoted rendered html this text will be quoted code annotate code inline rmarkdown `this text will appear as code` inline rendered html this text will appear as code inline evaluate r code inline a &lt;- 10 rmarkdown the value of parameter *a* is `r a` rendered html the value of parameter a is 10 images Provide either a path to a local image file or the URL of an image. rmarkdown ![](assets/cheat.png) rendered html resize images html in rmarkdown &lt;img src=&quot;assets/cheat.png&quot; width=&quot;200px&quot; /&gt; rendered html basic tables in markdown rmarkdown Table Header | Second Header - | - Cell 1 | Cell 2 Cell 3 | Cell 4 rendered html Table Header Second Header Cell 1 Cell 2 Cell 3 Cell 4 Check out handy online .md table converter links rmarkdown [Download R](http://www.r-project.org/) [RStudio](http://www.rstudio.com/) rendered html Download R RStudio mathematical expressions Supports mathematical notations through MathJax. You can write LaTeX math expressions inside a pair of dollar signs, e.g. $\\alpha+\\beta$ renders \\(\\alpha+\\beta\\). You can use the display style with double dollar signs: $$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$ \\[\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\\] 💻 Exercise: Part 3 Get more info on gapminder: Do some quick online research on Gapminder. A good places to start: https://www.gapminder.org/ Create a &quot;Background&quot; section using headers Write a short description Write a short description of the Gapminder project (feel free to copy, paste and edit information). Have a look at the gapminder site and especially the about page. Make use of markdown annotation to: highlight important information include links to sources or further information. Add an image Add an image related to Gapminder. have a look online for an image. include the source URL underneath for attribution. see if you can resize it. 🚦 Chunks &amp; Inline R code inserting new chunks You can quickly insert an R code chunk with: the keyboard shortcut Ctrl + Alt + I (OS X: Cmd + Option + I) the Add Chunk command in the RStudio toolbar by typing the chunk delimiters ```{r} and ```. chunk uses There are a lot of things you can do in a code chunk: you can produce text output, tables, or graphics. You have fine control over all these output via chunk options, which can be provided inside the curly braces (between ```{r and }). For example, you can choose hide text output via the chunk option results = 'hide', or set the figure height to 4 inches via fig.height = 4. Chunk options are separated by commas, e.g., ```{r, chunk-label, results=&#39;hide&#39;, fig.height=4} R code chunks execute code. They can be used as a means to render R output into documents or to simply display code for illustration (eg with option eval=FALSE). chunk notation chunk notation in .rmd ```{r chunk-name} print(&#39;hello world!&#39;) ``` rendered html code and output print(&#39;hello world!&#39;) ## [1] &quot;hello world!&quot; Chunks can be labelled with chunk names, names must be unique. chunk options for more details see http://yihui.name/knitr/ uses controlling whether code is displayed inline (echo setting) controlling whether code is evaluated (eval setting) controlling how figures are displayed (fig.width and fig.height settings) suppressing warnings and messages (warning and message settings) cacheing computations (cache setting) controlling whether code is extracted when using purl (purl settings) controlling code display with echo chunk notation in .rmd ```{r hide-code, echo=FALSE} print(&#39;hello world!&#39;) ``` rendered html code and output ## [1] &quot;hello world!&quot; controlling code evaluation with eval chunk notation in .rmd ```{r dont-eval, eval=FALSE} print(&#39;hello world!&#39;) ``` rendered html code and output print(&#39;hello world!&#39;) setting document level default options knitr::opts_chunk$set(echo = TRUE, warning = F, message = F) 💻 Exercise Part 4 For this exercise we’ll be accessing the gapminder data through the gapminder R package. Create an “Installation” section using headers Write installation instruction Write brief instructions (including code) for others to access the dataset in R. Have a look at the package documentation on GitHub for inspiration. In R we often need to describe a setup proceedure that involves specifying the installation of required packages. However, installation of packages in not handled in .Rmd! (For the moment, install packages through the console). In our case, we’ll want to include the code for installing the gapminder package but not evaluate it in the .Rmd. We also want to include the rest of the packages we want to use: “ggplot2”, “DT”, “skimr” 🚦 Displaying data There are many ways you can display data and data properties in an .Rmd. printing data.frames data(airquality) head(airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 printing tibbles One nice feature of using tibbles over data.frames is the tidy printing behaviour: library(tibble) as_tibble(airquality) ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 41 190 7.4 67 5 1 ## 2 36 118 8 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 ## # … with 143 more rows Displaying knitr::kable() tables We can use other packages to create html tables from our data. The simplest is to use the knitr::kable() function. library(knitr) data(airquality) kable(head(airquality), caption = &quot;New York Air Quality Measurements&quot;) Table 1: New York Air Quality Measurements Ozone Solar.R Wind Temp Month Day 41 190 7.4 67 5 1 36 118 8.0 72 5 2 12 149 12.6 74 5 3 18 313 11.5 62 5 4 NA NA 14.3 56 5 5 28 NA 14.9 66 5 6 Displaying interactive DT::datatable() tables You can display interactive html tables using function DT::datatable(): library(DT) data(airquality) datatable(airquality, caption = &quot;New York Air Quality Measurements&quot;) Summarising data with skimr::skim() Fuction skimr::skim() provides a simple approach to displaying summary statistics that can be quickly skimmed quickly to understand data. skimr::skim(airquality) Table 2: Data summary Name airquality Number of rows 153 Number of columns 6 _______________________ Column type frequency: numeric 6 ________________________ Group variables None Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Ozone 37 0.76 42.13 32.99 1.0 18.00 31.5 63.25 168.0 ▇▃▂▁▁ Solar.R 7 0.95 185.93 90.06 7.0 115.75 205.0 258.75 334.0 ▅▃▅▇▅ Wind 0 1.00 9.96 3.52 1.7 7.40 9.7 11.50 20.7 ▂▇▇▃▁ Temp 0 1.00 77.88 9.47 56.0 72.00 79.0 85.00 97.0 ▂▃▇▇▃ Month 0 1.00 6.99 1.42 5.0 6.00 7.0 8.00 9.0 ▇▇▇▇▇ Day 0 1.00 15.80 8.86 1.0 8.00 16.0 23.00 31.0 ▇▇▇▇▆ 💻 Exercise Part 5 Start a new section called &quot;Dataset&quot; Display an example of the dataset Make the gapminder data available by loading the gapminder package library(gapminder) Write a short description of the dataset What size is the data? (How many variables? How many rows of data points. See if you can extract and include such info inline) what type of object is it? (see ?class) Use some of the functions you’ve learnt to extract such information (eg ?dim, ?ncol etc). Summarise the data (e.g. ?summary, ?skimr) 🚦 plots By default, figures produced by R code will be placed immediately after the code chunk they were generated from. Let’s use ggplot2 to have a look to the relationship between a couple of variables. p &lt;- ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() p interactive plots with plotly Wraps nicely around plotting library ggplot2 library(plotly) ggplotly(p) 💻 Exercise Part 6a Replicate the plot above in your own index.Rmd but hide the code that generates them. Add a caption Experiment with controlling figure output width OPTIONAL Can you adapt the plotting code to use log10 transformed data? hint: explore the scale_... functions in ggplot2 (cheatsheet) Details on chunk arguments related to plotting Exercise Part 6b Publish your report on Rpubs Add you link to our hackmd 🚦 Advanced .Rmd reading chunks of code R -&gt; Rmd You can read in chunks of code from an annotated .R (or any other language) script using knitr::read_chunks() Chunks are defined by the following notation. Names must be unique. # - descriptive-chunk-name1 - code(&quot;you want to run as a chunk&quot;) # - descriptive-chunk-name2 - code(&quot;you want to run as a chunk&quot;) code in .R script hello-world.R hello-world.R # ---- demo-read_chunk ---- print(&quot;hello world&quot;) read chunks from hello-world.R knitr::read_chunk(here::here(&quot;demos&quot;,&quot;hello-world.R&quot;)) call chunk by name rmarkdown r chunk notation ```{r demo-read_chunk} ``` rendered html code and output print(&quot;hello world&quot;) ## [1] &quot;hello world&quot; Check chunks in the current session knitr:::knit_code$get() ## $`demo-read_chunk` ## [1] &quot;print(\\&quot;hello world\\&quot;)&quot; Extracting code from an .Rmd Rmd -&gt; R You can use knitr::purl() to tangle code out of an Rmd into an .R script. purl takes many of the same arguments as knit(). The most important additional argument is: documentation: an integer specifying the level of documentation to go the tangled script: 0 means pure code (discard all text chunks) 1 (default) means add the chunk headers to code 2 means add all text chunks to code as roxygen comments purl(&quot;file-to-extract-code-from.Rmd&quot;, documentation = 0) extract using purl Here i’m running a loop to extract the code in demo-rmd.Rmd for each documentation level file &lt;- here::here(&quot;demos&quot;,&quot;demo-rmd.Rmd&quot;) for(docu in 0:2){ knitr::purl(file, output = paste0(gsub(&quot;.Rmd&quot;, &quot;&quot;, file), &quot;_&quot;, docu, &quot;.R&quot;), documentation = docu, quiet = T) } demo-rmd_0.R knitr::opts_chunk$set(echo = TRUE) summary(cars) plot(pressure) demo-rmd_1.R ## ----setup, include=FALSE------------------------------------------------ knitr::opts_chunk$set(echo = TRUE) ## ----cars---------------------------------------------------------------- summary(cars) ## ----pressure, echo=FALSE------------------------------------------------ plot(pressure) demo-rmd_2.R #&#39; --- #&#39; title: &quot;Untitled&quot; #&#39; author: &quot;Anna Krystalli&quot; #&#39; date: &quot;3/23/2018&quot; #&#39; output: #&#39; html_document: #&#39; toc: true #&#39; toc_float: true #&#39; theme: cosmo #&#39; highlight: textmate #&#39; #&#39; --- #&#39; ## ----setup, include=FALSE------------------------------------------------ knitr::opts_chunk$set(echo = TRUE) #&#39; #&#39; ## R Markdown #&#39; #&#39; #&#39; This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;http://rmarkdown.rstudio.com&gt;. #&#39; #&#39; When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: #&#39; ## ----cars---------------------------------------------------------------- summary(cars) #&#39; #&#39; ## Including Plots #&#39; #&#39; You can also embed plots, for example: #&#39; ## ----pressure, echo=FALSE------------------------------------------------ plot(pressure) #&#39; #&#39; Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot. #&#39; #&#39; 💻 Exercise: Part 7* read in a chunk Open an .R script Cut the code from one or more of your chunks and paste it into the .R script Annotate the code up as named chunk(s) Read the chunk(s) in your .R script into your .Rmd (?read_chunk()) Include the code in your .Rmd workflow by labelling an empty chunk with your chunk(s) name(s) purl your document Once your document is ready, try and extract the contents of your .Rmd into an .R script. ?purl 🚦 html in rmarkdown marking up with html tags This text marked up in html &lt;strong&gt;Bold text&lt;/strong&gt; renders to this Bold text **This text marked up with Bootstrap alert css classes &lt;div class=&quot;alert alert-warning&quot;&gt;&lt;small&gt;this a is warning message&lt;/small&gt;&lt;/div&gt; renders to this a is warning message &lt;div class=&quot;alert alert-success&quot;&gt;&lt;small&gt;this a is success message&lt;/small&gt;&lt;/div&gt; renders to this a is success message embedding tweets This snipped copied from twitter in the embed format &lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;How cool does this tweet look embedded in &lt;a href=&quot;https://twitter.com/hashtag/rmarkdown?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#rmarkdown&lt;/a&gt;! 😎&lt;/p&gt;&amp;mdash; annakrystalli (@annakrystalli) &lt;a href=&quot;https://twitter.com/annakrystalli/status/977209749958791168?ref_src=twsrc%5Etfw&quot;&gt;March 23, 2018&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; renders to this How cool does this tweet look embedded in #rmarkdown! 😎 — annakrystalli (@annakrystalli) March 23, 2018 Embbed gifs, videos, widgets in this way Parting words Getting help with markdown To get help, you need a reproducible example github issues stackoverflow slack channels discussion boards reprex install.packages(&quot;reprex&quot;) Use function reprex::reprex() to produce a reproducible example in a custom markdown format for the venue of your choice &quot;gh&quot; for GitHub (default) &quot;so&quot; for StackOverflow, &quot;r&quot; or &quot;R&quot; for a runnable R script, with commented output interleaved. using reprex Copy the code you want to run. all required variables must be defined and libraries loaded In the console, call the reprex function reprex::reprex() the code is executed in a fresh environment and “code + commented output” is returned invisibly on the clipboard. Paste the result in the venue of your choice. Once published it will be rendered to html. bookdown Authoring with R Markdown. Offers: cross-references, citations, HTML widgets and Shiny apps, tables of content and section numbering The publication can be exported to HTML, PDF, and e-books (e.g. EPUB) Can even be used to write thesis! &lt;img src=“assets/logo_bookdown.png”, width=“200px”/&gt; &lt;img src=“assets/cover_bookdown.jpg”, width=“200px”/&gt; pkgdown For buidling package documentation Can use it to document any functional code you produce and demonstrate it’s us ethrough vignettes workflowr pkg Build analyses websites and organise your project The workflowr R package makes it easier for researchers to organize their projects and share their results with colleagues. ] blogdown For creating and mantaining blogs. Check out https://awesome-blogdown.com/, a curated list of awesome #rstats blogs in blogdown for inspiration! bookdown For creating and mantaining online books rOpenSci Software Review policies Geocomputation in R Thesisdown An updated R Markdown thesis template using the bookdown package Resources R Markdown: The Definitive guide Rmarkdown documentation Rmarkdown html_document format documentation Rstudio Rmarkdown cheatsheet Reproducible Research coursera MOOC Producing html documents from .R scripts using knitr::spin Solutions: My example gapminder-analysis Rendered html gapminder-analysis Rmd "],
["plotting-with-ggplot2.html", "Plotting with ggplot2", " Plotting with ggplot2 "],
["version-control.html", "(PART) Version Control", " (PART) Version Control "],
["version-control-with-git.html", "Version Control with Git Background What is git? 🤔 Why use it in research? What is GitHub 🤔 Git, Github &amp; Rstudio Demo How does Git work? 💻 Configure git &amp; GitHub Configure git 🚦 Set up GITHUB PAT Turn our project into a repository 🚦 Commiting files Add files Commit changes 🚦 Create a README Edit README 🚦 Create repository on GitHub Create repository push files 🚦 Tracking changes Making a change to our gapminder-analysis.Rmd Commit your changes 🚦 Host content on GitHub Go to repo Settings Enable gh-pages 🚦 Making changes on GitHub Create LICENSE Add link to analysis index.html to README 🚦 Pull changes locally 🚦 Deleting files .gitignore gitignore regex Further Resources Never forget", " Version Control with Git Background Hands up - who has heard of version control software? What do you think it does? What is Version control? 🤔 The management of changes to documents, computer programs, large web sites, and other collections of information. Examples: Numbering of book editions Wikipedia’s Page history Where did it come from? The need for a logical way to organize and control revisions has existed for almost as long as writing has existed, but revision control became much more important, and complicated when the era of computing began Elements of a Version Control system Changes are usually identified by a number or letter code, termed the “revision number” Each revision is associated with a timestamp and the person making the change. Only changes to a file are recorded rather than saving a whole new copy. Revisions can be compared, restored, and with some types of files, merged. What is git? 🤔 Open source (free to use) Version control software. Usually accessed via the command line, or a client program. Where did it come from? Git development began in 2006 after many developers of the Linux kernel gave up access to BitKeeper (at the time the best but proprietary) Linus Torvalds on the name git: &quot;I’m an egotistical bastard, and I name all my projects after myself. First ‘Linux’, now ‘git’ More on the name in the source code original readme file Why use it in research? Exhibit A Image: xkcd CC BY-NC 2.5 What is GitHub 🤔 A website that allows you to store your Git repositories online and makes it easy to collaborate with others. They also provide other services like issue (bug) tracking and wikis. Similar services are GitLab and BitBucket. Why use it in research: To enable collaboration and track contributions images: Mozilla Science Lab CC-BY 4.0 Acts as a remote back-up Facilitates transparency Facilitates project management Facilitates sharing and collaboration Super-charges innovation by Open Sourcing Science Mozilla &amp; Working Open Open Source Basics Reinventing Discovery Macroecological and macroevolutionary patterns emerge in the universe of GNU/Linux operating systems Anatomy of GitHub Repo Readme files. Create a README.md file to explain what your project is, and how to install and use it. README.md is the file that is automatically displayed when you open a GitHub repo. License. Without some sort of licence, the contents of the repository are technically closed. Some allow users of the code to do anything they like with their code - these are known as permissive licences. Examples are the MIT Licence or Apache. https://choosealicense.com/ - does what it says on the tin and helps you choose a licence. Here are some resources to help you choose: https://tldrlegal.com/ - plain english explanations of licences in bullet form. Contributing guide - make a file called CONTRIBUTING.md and guidelines for contributors so they know what they should do if they want to help you out. Code of Conduct - good projects have codes of conduct to make sure that people are treated well. Github has an Code of Conduct wizard to make it easy to add one. Issues - use GitHub issues to record and discuss tasks. Git, Github &amp; Rstudio Before: git only through the terminal Rstudio &amp; usethis to the rescue! Rstudio + usethis 📦 == heavenly Git &amp; GitHub Initialise Rstudio project with Git by just checking a box! Forgot to? use usethis::use_git() visual panel to easily see the status of all your files interactive navigation through file version history Demo How does Git work? When a local directory becomes initialised with git, a hidden .git folder is added to it. it’s now called a repository New copies of files you tell git to track will be added to that .git folder. After adding, git will track any modifications to those files first commit - whole file added Any file unknown to git will have a yellow ? box next to it. The first time you commit a file you are adding it to .git, effectively telling it to start tracking the file second commit - only difference highlighted All changes have been committed so the git panel is clear Enough theory, how about in practice! 💻 Configure git &amp; GitHub Configure git First, git needs to know who you are so your commits can be attributed to you. usethis to the rescue again! Check your configuration usethis::use_git_config() Set your configuration Use your github username and and the email you used to sign-up on GitHub usethis::use_git_config( user.name = &quot;Jane&quot;, user.email = &quot;jane@example.org&quot;) 🚦 Set up GITHUB PAT To authenticate with GitHub, you’ll also need a Personal Authorisation Token (PAT). usethis::browse_github_pat() will open up the GitHub panel to generate your PAT. Copy it and paste it into your .Renviron file as system variable GITHUB_PAT. usethis::edit_r_environ() Use edit_r_environ() to open and edit your .Renviron file Turn our project into a repository If you didn’t initialise git at the beginning of your project, you can do so now with: usethis::use_git() This however commits everything in one go. So not ideal! I recommend using git from the start of every project. 🚦 Commiting files In our project, let’s have a look at the Rstudio Git tab. It shows all the files currently in the folder. The yellow ? indicates none of the files have been added to git yet. Add files To commit changes in a file just select it in the git pane. When changes to a file are commited for the first time, the whole file is indicated as Added (green A). Commit changes Click on commit and write an appropriate commit message: 🚦 Create a README Our repository also needs a README. We only need a simple plain markdown (.md) file for our README. We can create a template using usethis::use_readme_md() usethis::use_readme_md() Edit README Adapt the template, adding a short description about your project. Add and commit your new README 🚦 Create repository on GitHub Create repository Now that we have set up a GITHUP_PAT, we can use function usethis::use_github() to create a GitHub repository for our project: usethis::use_github(protocol = &quot;https&quot;) push files Click on the ⬆️ button on the Git tab to push our changes up to our newly minted repository Let’s go have a look at the history 🕒 🚦 Tracking changes Making a change to our gapminder-analysis.Rmd In the last plot of your .index.Rmd, see if you can add a smooth for each continent to generate the plot below (should be just one extra ggplot2 function added to the plot). Look for the appropriate geom_* function. See also if you can include an interactive plotly version Commit your changes On the commit window: Have a look at the differences Have a look at the history 🚦 Host content on GitHub Let’s head to the repo and have a look at what we’ve shared. To host our html content on GitHub, we need to enable gh-pages in our repository. Go to repo Settings Enable gh-pages Review setup Ensure the Enforce HTTPS option is selected. Click on the link displayed and go check out your work! Copy the link. In the main repo page, edit the page details at the top and paste copied the url in the website field. 🚦 Making changes on GitHub We can also create new documents and edit existing ones on GitHub. Create LICENSE Let’s create also create a LICENSE in our repository. Click on New File Start typing LICENSE A choose license template will button will pop up on the right. Click on it. Choose license On the left side panel, choose the MIT License Review licence Review the details in the license. Scroll down to commit it Commit License Commit the LICENSE directly to your master branch Once commited, the LICENSE file should be visible in the repo Add link to analysis index.html to README Let’s edit the README.md on GitHub to add Commit the changes directly into the master again. 🚦 Pull changes locally Finally, let’s pull the changes back down to our local repository by clicking the ⬇️ button on the Git tab. 🚦 Deleting files Create a new file, any type of file. Commit it. Delete it Commit the deletion Look back through the history .gitignore There may be files that you don’t want to commit to git, e.g. data files that are too large documents with sensitive information (eg authorisation tokens etc) intermediate files that you don’t need to save copies of. Tell git to ingnore them by adding them to the .gitignore file. gitignore regex You can use regex in .gitignore files to ignore files according to a pattern. *.html will ignore any file ending in .html prefix “!” which negates the pattern data/* !data/commit-this.csv Git tips commit early, commit often commit logical bits of work together write meaninful messages Further Resources Git-it Happy with Git Oh Shit Git Never forget "],
["practical-github-rstudio-for-collaborative-coding.html", "Practical: GitHub &amp; Rstudio for collaborative coding EvoLottery Clone Github repo", " Practical: GitHub &amp; Rstudio for collaborative coding EvoLottery Welcome to the evolutionary lottery of skull and beak morphology Beak and skull shapes in birds of prey (“raptors”) are strongly coupled and largely controlled by size. In this exercise, each participant will fork a GitHub repo, and contribute a file required to simulate the evolutionary trajectory of an imaginary species’ body size. We’ll use GitHub to collate all species files and plot them all up together at the end! We’ll also discover the skull and beak shapes associated with each simulated species size. Start! Clone Github repo 💻 Clone a GitHub repo Start with GitHub repo https://GitHub.com/RSE-Sheffield/collaborative_GitHub_exercise Fork it make your own copy of the repository on GitHub. Fork are linked and traceable GitHub makes a copy into your account 🚦 Clone repo copy repo link to create a new Rstudio project from the repository. Create new project in Rstudio Checkout from version control repository Clone project from a git repository Paste repo link copied from GitHub into Repository URL field. Click Create Project. Rstudio project now contains all files from the GitHub repo. 🚦 Make a change to the repo make a copy of params_tmpl.R open params/params_tmpl.R SAVE AS NEW .R script in params/ folder Use species name of your choice to name new file. Please DO NOT OVERWRITE params/params_tmpl.R. 🚦 Edit file Edit file with parameters of your choice and save. The parameters each participants need to supply are: sig2: A numeric value greater than 0 but smaller than 5 species.name: a character string e.g. &quot;anas_krystallinus&quot;. Try to create a species name out of your name! color: a character string e.g. &quot;red&quot;, &quot;#FFFFFF&quot; (Check out list of colours in R) NB: remember to save the changes to your file 🚦 Commit changes locally to git In the git tab, select the new file you created and click Commit. Please ONLY COMMIT YOUR NEW FILE Write an informative commit message and click Commit your new file has now been commited Push changes to GitHub on the git tab click ⇧ to push changes to GitHub changes have now been updated in the GitHub repo 🚦 create pull request In your repository, create new pull request to merge fork to master repo (ie the original repo you forked) GitHub checks whether your requested merge creates any coflicts. If all is good, click on Create pull request Write an informative message explaining your changes to the master repo administrators. Click on Create pull request The repository owner will then review your PR and either merge it in or respond with some guidance if they spot a problem. Check original repo to see your merged changes We’ll merge all contributions and plot them together at the end! "],
["packaging-functionality.html", "Packaging functionality R Package Structure R Package conventions: Software Engineering approach Anatomy of an R package DESCRIPTION file Dependency management R/ Document functions with Roxygen tests/ 💻Create your first package 🚦 Functions in the R/ dir 🚦 Roxygen documentation 🚦 Personalise function Add some fun! 🚦 Check package integrity 🚦 Add dependencies Add License 🚦 Add Test create test file Write test 🚦 Complete package metadata Authors Add a title and description Add a date 🚦 Create README Commit and push to GitHub 🚦 Create documentation site", " Packaging functionality R Package Structure Used to share functionality with the R community Useful conventions Useful software development tools Easy publishing through GitHub R Package conventions: metadata: in the DESCRIPTION file functions in .R scripts in the R/ folder tests in the tests/ folder Documentation: functions using Roxygen notation workflows using .Rmd documents in the vignettes/ folder Software Engineering approach Following conventions allows us to make use of automated tools for: Checking and testing code Producing documentation for code and workflows Publishing, distributing and citing code Anatomy of an R package Let’s use pkgreviewr, a package I authored to help automate some aspects of the rOpenSci review process, as an example to examine some elements of what makes a package: DESCRIPTION file Capture metadata around the package - Functionality description - Creators - License Package: pkgreviewr Type: Package Title: rOpenSci package review project template Version: 0.1.1 Authors@R: c(person(&quot;Anna&quot;, &quot;Krystalli&quot;, email = &quot;annakrystalli@googlemail.com&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;)), person(&quot;Maëlle&quot;, &quot;Salmon&quot;, email = &quot;maelle.salmon@yahoo.se&quot;, role = &quot;aut&quot;)) Description: Creates files and collects materials necessary to complete an rOpenSci package review. Review files are prepopulated with review package specific metadata. Review package source code is also cloned for local testing and inspection. License: GPL-3 + file LICENSE URL: https://github.com/ropenscilabs/pkgreviewr BugReports: https://github.com/ropenscilabs/pkgreviewr/issues Encoding: UTF-8 LazyData: true Imports: devtools, git2r (&gt;= 0.23.0), usethis (&gt;= 1.2.0), here, reprex, gh, base64enc, whoami, magrittr, covr, goodpractice, assertthat, httr, rstudioapi, clipr, clisymbols, crayon, dplyr, glue, fs, urltools, shiny Suggests: testthat, mockery, knitr, rmarkdown RoxygenNote: 6.1.1 Remotes: ropensci/git2r VignetteBuilder: knitr Roxygen: list(markdown = TRUE) citation citation(&quot;pkgreviewr&quot;) ## ## To cite package &#39;pkgreviewr&#39; in publications use: ## ## Anna Krystalli and Maëlle Salmon (2019). pkgreviewr: rOpenSci package ## review project template. R package version 0.1.2. ## https://github.com/ropenscilabs/pkgreviewr ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {pkgreviewr: rOpenSci package review project template}, ## author = {Anna Krystalli and Maëlle Salmon}, ## year = {2019}, ## note = {R package version 0.1.2}, ## url = {https://github.com/ropenscilabs/pkgreviewr}, ## } Dependency management It’s the job of the DESCRIPTION to list the packages that your package needs to work. Imports: devtools, git2r (&gt;= 0.23.0), usethis (&gt;= 1.2.0), here, reprex, gh, base64enc, whoami, magrittr, covr, goodpractice, assertthat, httr, rstudioapi, clipr, clisymbols, crayon, dplyr, glue, fs, urltools, shiny Imports are necessary dependencies for the functions in your package to work Suggests: testthat, mockery, knitr, rmarkdown Suggests are dependencies that are not necessary for the functions in your package but might be neccessary to run all the vignettes or tests in your package R/ Keep all functions in R scripts in R/ folder . ├── github.R ├── pkgreview.R ├── pkgreviewr-package.R ├── render-templates.R ├── rmd-utils.R ├── style.R └── utils.R 0 directories, 7 files example function script Create a new function .R file in the R/ folder library(usethis) use_r(&quot;add&quot;) R └── add.R 0 directories, 1 files Document functions with Roxygen Document functions with Roxygen notation Automatically create help files on build #&#39; Add together two numbers. #&#39; #&#39; @param x A number. #&#39; @param y A number. #&#39; @return The sum of x and y. #&#39; @examples #&#39; add(1, 1) #&#39; add(10, 1) add &lt;- function(x, y) { x + y } tests/ Tests provide confidence in what the code is doing. Contents of pkgreviewr test folder . ├── testthat │ ├── setup.R │ ├── test-create-pkgreview.R │ ├── test-gh-calls.R │ ├── test-render-templates.R │ └── test-setup.R └── testthat.R 1 directory, 6 files Example test use_test(&quot;add&quot;) tests ├── testthat │ ├── test-add.R └── testthat.R context(&quot;test-add&quot;) test_that(&quot;add works&quot;, { expect_equal(add(2, 2), 4) }) The R package structure can help with providing a logical organisation of files, by providing a set of standard locations for certain types of files. To work with packages in RStudio we use the Build pane, which includes a variety of tools for building, documenting and testing packages. This will appear if Rstudio recognises the project as an R package. 💻Create your first package Let’s go ahead and create our first package! We do that as we would any project, but this time we select R package instead of New Project. Call your package mypackage. File &gt; New Project… &gt; New Directory &gt; R package &gt; mypackage Your new project should have the following structure. The build pane should also be visible. . ├── DESCRIPTION ├── NAMESPACE ├── R │ └── hello.R ├── man │ └── hello.Rd └── mypackage.Rproj 2 directories, 5 files 🚦 Functions in the R/ dir Let’s inspect hello.R it contains a function that takes now arguments and prints hello world to the console when called. The comments above are just that, comments and don’t serve any functional purpose. # Hello, world! # # This is an example function named &#39;hello&#39; # which prints &#39;Hello, world!&#39;. # # You can learn more about package authoring with RStudio at: # # http://r-pkgs.had.co.nz/ # # Some useful keyboard shortcuts for package authoring: # # Build and Reload Package: &#39;Cmd + Shift + B&#39; # Check Package: &#39;Cmd + Shift + E&#39; # Test Package: &#39;Cmd + Shift + T&#39; hello &lt;- function() { print(&quot;Hello, world!&quot;) } Install package. You can install a package locally from it’s source code with function install() library(devtools) install(&quot;.&quot;) You can now load it like any other package… library(&quot;mypackage&quot;) And use your function! hello() ## [1] &quot;Hello, world!&quot; 🚦 Roxygen documentation Roxygen2 allows you to write specially-structured comments preceeding each function definition to document: the inputs and outputs a description of what it does an example of how to use it These are processed automatically to produce .Rd help files for your functions and control which functions are exported to the package NAMESPACE. Let’s document our example function. First, clear the demo comments above the function and all contents of the exampleNAMESPACE. Also delete the file in the man folder. Insert Roxygen skeleton You can insert a Roxygen skeleton by placing the curson with a function and clicking: Code &gt; Insert Roxygen Skeleton #&#39; Title #&#39; #&#39; @return #&#39; @export #&#39; #&#39; @examples hello &lt;- function() { print(&quot;Hello, world!&quot;) } Roxygen basics roxygen notation indicated by beginning line with #'. First line will be the title for the function. After title, include a blank #' line and then write a longer description. @param argument_name description of the argument. @return description of what the function returns. @export tells Roxygen2 to add this function to the NAMESPACE file, so that it will be accessible to users. @examples allows to include example of how to use a function Complete Roxygen documentation #&#39; Hello World! #&#39; #&#39; Print hello greeting #&#39; @return prints hello greeting to console #&#39; @export #&#39; #&#39; @examples #&#39; hello() hello &lt;- function() { print(&quot;Hello, world!&quot;) } Autogenerate documentation Use function devtools::document() to create documentation. This re-creates a hello.Rd helpfile in the man/ folder and populates the NAMESPACE with our functions devtools::document() Click Install and Restart to re-install the package and make the documentation available. You can configure your build tools in the Global Options to automatically build documentation every time you Install &amp; Rebuild 🚦 Personalise function Let’s go a step further and customise our function so that the greeting is from ourselves! #&#39; Hello World! #&#39; #&#39; Print hello greeting #&#39; @return prints hello greeting to console from me #&#39; @export #&#39; #&#39; @examples #&#39; hello() hello &lt;- function() { print(&quot;Hello, world from Anna&quot;) } Add some fun! Programming is most useful for having fun. So let’s make our function extra fun! We’ll use package cowsay install.packages(&quot;cowsay&quot;) which has a single function say, which does this… cowsay::say(&quot;Say whaaaaaat?&quot;, by = &quot;shark&quot;) ## ## -------------- ## Say whaaaaaat? ## -------------- ## \\ ## \\ ## \\ ## /&quot;&quot;-._ ## . &#39;-, ## : &#39;&#39;, ## ; * &#39;. ## &#39; * () &#39;. ## \\ \\ ## \\ _.---.._ &#39;. ## : .&#39; _.--&#39;&#39;-&#39;&#39; \\ ,&#39; ## .._ &#39;/.&#39; . ; ## ; `-. , \\&#39; ## ; `, ; ._\\ ## ; \\ _,-&#39; &#39;&#39;--._ ## : \\_,-&#39; &#39;-._ ## \\ ,-&#39; . &#39;-._ ## .&#39; __.-&#39;&#39;; \\...,__ &#39;. ## .&#39; _,-&#39; \\ \\ &#39;&#39;--.,__ &#39;\\ ## / _,--&#39; ; \\ ; \\^.} ## ;_,-&#39; ) \\ )\\ ) ; ## / \\/ \\_.,-&#39; ; ## / ; ## ,-&#39; _,-&#39;&#39;&#39;-. ,-., ; PFA ## ,-&#39; _.-&#39; \\ / |/&#39;-._...--&#39; ## :--`` )/ ## &#39; ## 😜 So let’s create a function that randomly chooses one of the animals available in cowsay to deliver the greeting, and also allow the user to customise who the recipient of the greeting is #&#39; Hello World! #&#39; #&#39; Print personalised hello greeting from me. #&#39; #&#39; @param name character string. Your name! #&#39; #&#39; @return prints hello greeting to console #&#39; @export #&#39; #&#39; @examples #&#39; hello() #&#39; hello(&quot;Lucy Elen&quot;) hello &lt;- function(name = NULL) { # create greeting if(is.null(name)){name &lt;- &quot;world&quot;} greeting &lt;- paste(&quot;Hello&quot;, name, &quot;from Anna!&quot;) # randomly sample an animal animal_names &lt;- names(cowsay::animals) i &lt;- sample(1:length(animal_names), 1) cowsay::say(greeting, animal_names[i]) } Document, Install and restart to load our changes hello(&quot;y&#39;all&quot;) ## ## ----- ## Hello y&#39;all from Anna! ## ------ ## \\ ## \\ ## ____ ## _.&#39; : `._ ## .-.&#39;`. ; .&#39;`.-. ## __ / : ___\\ ; /___ ; \\ __ ## ,&#39;_ &quot;&quot;--.:__;&quot;.-.&quot;;: :&quot;.-.&quot;:__;.--&quot;&quot; _`, ## :&#39; `.t&quot;&quot;--.. &#39;&lt;@.`;_ &#39;,@&gt;` ..--&quot;&quot;j.&#39; `; ## `:-.._J &#39;-.-&#39;L__ `-- &#39; L_..-;&#39; ## &quot;-.__ ; .-&quot; &quot;-. : __.-&quot; ## L &#39; /.------.\\ &#39; J ## &quot;-. &quot;--&quot; .-&quot; ## __.l&quot;-:_JL_;-&quot;;.__ ## .-j/&#39;.; ;&quot;&quot;&quot;&quot; / .&#39;\\&quot;-. ## .&#39; /:`. &quot;-.: .-&quot; .&#39;; `. ## .-&quot; / ; &quot;-. &quot;-..-&quot; .-&quot; : &quot;-. ## .+&quot;-. : : &quot;-.__.-&quot; ;-._ \\ ## ; \\ `.; ; : : &quot;+. ; ## : ; ; ; : ; : \\: ## ; : ; : ;: ; : ## : \\ ; : ; : ; / :: ## ; ; : ; : ; : ;: ## : : ; : ; : : ; : ; ## ;\\ : ; : ; ; ; ; ## : `.&quot;-; : ; : ; / ; ## ; -: ; : ; : .-&quot; : ## :\\ \\ : ; : \\.-&quot; : ## ;`. \\ ; : ;.&#39;_..-- / ; ## : &quot;-. &quot;-: ; :/.&quot; .&#39; : ## \\ \\ : ;/ __ : ## \\ .-`.\\ /t-&quot;&quot; &quot;:-+. : ## `. .-&quot; `l __/ /`. : ; ; \\ ; ## \\ .-&quot; .-&quot;-.-&quot; .&#39; .&#39;j \\ / ;/ ## \\ / .-&quot; /. .&#39;.&#39; ;_:&#39; ; ## :-&quot;&quot;-.`./-.&#39; / `.___.&#39; ## \\ `t ._ / bug ## &quot;-.t-._:&#39; ## 🚦 Check package integrity An important part of the package development process is R CMD check. R CMD check automatically checks your code and can automatically detects many common problems that we’d otherwise discover the hard way. To check our package, we can: use devtools::check() press Ctrl/Cmd + Shift + E click on the ✅Check tab in the Build panel. This: Ensures that the documentation is up-to-date by running devtools::document(). Bundles the package before checking it. More info on checks here. Both these run R CMD check which return three types of messages: ERRORs: Severe problems that you should fix regardless of whether or not you’re submitting to CRAN. WARNINGs: Likely problems that you must fix if you’re planning to submit to CRAN (and a good idea to look into even if you’re not). NOTEs: Mild problems. If you are submitting to CRAN, you should strive to eliminate all NOTEs, even if they are false positives. Let’s Check our package: Click on the Check button (📋 ✅) ── R CMD check results ──────────────────────────────────── mypackage 0.1.0 ──── Duration: 8.4s ❯ checking DESCRIPTION meta-information ... WARNING Non-standard license specification: What license is it under? Standardizable: FALSE ❯ checking dependencies in R code ... WARNING &#39;::&#39; or &#39;:::&#39; import not declared from: ‘cowsay’ 0 errors ✔ | 2 warnings ✖ | 0 notes ✔ Error: R CMD check found WARNINGs Execution halted Exited with status 1. Aha, so our checks have thrown up some warnings! First, it’s telling us we haven’t added a LICENSE. It’s also telling us that we have a dependency (import) from package cowsay which we haven’t documented in the DESCRIPTION file. usethis to the rescue! 🚦 Add dependencies Add cowsay as a dependency. usethis::use_package(&quot;cowsay&quot;) ✔ Setting active project to &#39;/Users/Anna/Desktop/mypackage&#39; ✔ Adding &#39;cowsay&#39; to Imports field in DESCRIPTION ● Refer to functions with `cowsay::fun()` Add License usethis::use_mit_license() Check again…All should be good! ── R CMD check results ──────────────────────────────────── mypackage 0.1.0 ──── Duration: 9.3s 0 errors ✔ | 0 warnings ✔ | 0 notes ✔ R CMD check succeeded 🚦 Add Test Testing is a vital part of package development. It ensures that our code does what you want it to do. Once you’re set up with a testing framework, the workflow is simple: Modify your code or tests. Test your package with Ctrl/Cmd + Shift + T or devtools::test(). Repeat until all tests pass. create test file To create a new test file (and the testing framework if required), use function usethis::use_test(). It’s good practice to name the test files after the .R files containing the functions being tested. use_test(&quot;hello&quot;) ✔ Setting active project to &#39;/Users/Anna/Documents/workflows/workshops/materials/mypackage&#39; ✔ Adding &#39;testthat&#39; to Suggests field in DESCRIPTION ✔ Creating &#39;tests/testthat/&#39; ✔ Writing &#39;tests/testthat.R&#39; ✔ Writing &#39;tests/testthat/test-hello.R&#39; ● Modify &#39;tests/testthat/test-hello.R&#39; This just created the following folders and files tests ├── testthat │ └── test-hello.R └── testthat.R 1 directory, 2 files It also added testthat to the suggested packages in the DESCRIPTION file. Suggests: testthat That’s because you don’t need test that to run the functions in mypackage, but you do if you want to run the tests. When the tests are run (either through running devtools::test(), clicking on More &gt; Test Package in the Build panel or Cmd/Ctrl + Shift + T), the code in each test script in directory testthat is run. test-hello.R Let’s load the library so we can explore the testthat testing framework library(testthat) context(&quot;test-hello&quot;) test_that(&quot;multiplication works&quot;, { expect_equal(2 * 2, 4) }) If the test doesn’t pass it throws an error context(&quot;test-hello&quot;) test_that(&quot;multiplication works&quot;, { expect_equal(2 * 2, 5) }) ## Error: Test failed: &#39;multiplication works&#39; ## * &lt;text&gt;:4: 2 * 2 not equal to 5. ## 1/1 mismatches ## [1] 4 - 5 == -1 Write test Let’s write a simple test to check that we are getting an expected output type. The first thing to note, looking at the say() documentation is that it takes an argument type which allows us to specify the output we want. It defaults message which means the output of the function is returned as a message. We can therefore use testthat::expect_message() context(&quot;test-hello&quot;) test_that(&quot;hello works&quot;, { expect_message(hello()) }) ## ## ------------- ## Hello world from Anna! ## -------------- ## \\ ## \\ ## \\ ## _____________________ _____________________ ## `-._ \\ |\\__/| / _.-&#39; ## \\ \\ | | / / ## \\ `-_______/ \\_______-&#39; / ## | | ## | | ## | | ## / \\ ## /_____________ _____________\\ ## `----._ _.----&#39; ## `--. .--&#39; ## `-. .-&#39; ## \\ / :F_P: ## \\ / ## \\/ ## Error: Test failed: &#39;hello works&#39; ## * &lt;text&gt;:4: `hello()` did not produce any messages. Now let’s test our package devtools::test() Success! ==&gt; devtools::test() Loading mypackage Testing mypackage ✔ | OK F W S | Context ✔ | 1 | test-hello ══ Results ════════════════════════════════════════════════════════ OK: 1 Failed: 0 Warnings: 0 Skipped: 0 🚦 Complete package metadata Let’s head to the DESCRIPTION file and complete the details. Authors First let’s complete the authors. Remove the current author and maintainer lines and replace it with the following line: Authors@R: person(&quot;First&quot;, &quot;Last&quot;, email = &quot;first.last@example.com&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;)) completed with your own details Add a title and description Complete the title and description fields with appropriate details. If you want to form a paragraph of text, make sure do indent the hanging lines by 4 spaces (one tab). And make sure that your Description field ends in a full-stop. Add a date Use today’s date in ISO format, ie 2019-04-10. This will populate a citation entry for us. Completed DESCRIPTION The complete DESCRIPTION file should look something like this: Package: mypackage Type: Package Title: Customised greetings from me! Version: 0.1.0 Authors@R: person(&quot;Anna&quot;, &quot;Krystalli&quot;, email = &quot;annakrystalli@googlemail.com&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;)) Description: Prints a customised greeting from myself, delivered by a friend. License: MIT + file LICENSE Encoding: UTF-8 LazyData: true RoxygenNote: 6.1.1 Imports: cowsay Suggests: testthat Date: 2019-04-10 Check your package. If all is good, document, install and restart! Now, check you’re package’s citation: citation(&quot;mypackage&quot;) ## ## To cite package &#39;mypackage&#39; in publications use: ## ## Anna Krystalli (2019). mypackage: Customised greetings from me!. R ## package version 0.1.0. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {mypackage: Customised greetings from me!}, ## author = {Anna Krystalli}, ## year = {2019}, ## note = {R package version 0.1.0}, ## } 🚦 Create README The final document you will need for your package is a README. usethis::use_readme_rmd() ✔ Writing &#39;README.Rmd&#39; ✔ Adding &#39;^README\\\\.Rmd$&#39; to &#39;.Rbuildignore&#39; ● Modify &#39;README.Rmd&#39; ✔ Writing &#39;.git/hooks/pre-commit&#39; Because it’s an .Rmd but GitHub can only display an md document as it’s landing page, this is a special .Rmd that renders to a markdown document rather than html. The function adds a check to .git to ensure you commit an up to date version on the md when you commit changes to the .Rmd. Complete the README, including an example. Commit and push to GitHub Now you have everything you need to share your package on GitHub so commit and push it up. Anyone will be able to install it using, eg: devtools::install_github(&quot;annakrystalli/mypackage&quot;) 🚦 Create documentation site You can use package pkgdown to create an online site for your documentation: install.packages(&quot;pkgdown&quot;) pkgdown::build_site() ══ Building pkgdown site ════════════════════════════════════════════ Reading from: &#39;/Users/Anna/Documents/workflows/dummy/mypackage&#39; Writing to: &#39;/Users/Anna/Documents/workflows/dummy/mypackage/docs&#39; ── Initialising site ──────────────────────────────────────────────── Copying &#39;../../../../../../Library/Frameworks/R.framework/Versions/3.5/Resources/library/pkgdown/assets/docsearch.css&#39; to &#39;docsearch.css&#39; Copying &#39;../../../../../../Library/Frameworks/R.framework/Versions/3.5/Resources/library/pkgdown/assets/docsearch.js&#39; to &#39;docsearch.js&#39; Copying &#39;../../../../../../Library/Frameworks/R.framework/Versions/3.5/Resources/library/pkgdown/assets/link.svg&#39; to &#39;link.svg&#39; Copying &#39;../../../../../../Library/Frameworks/R.framework/Versions/3.5/Resources/library/pkgdown/assets/pkgdown.css&#39; to &#39;pkgdown.css&#39; Copying &#39;../../../../../../Library/Frameworks/R.framework/Versions/3.5/Resources/library/pkgdown/assets/pkgdown.js&#39; to &#39;pkgdown.js&#39; ── Building home ──────────────────────────────────────────────────── Writing &#39;authors.html&#39; Reading &#39;LICENSE.md&#39; Writing &#39;LICENSE.html&#39; Writing &#39;LICENSE-text.html&#39; Reading &#39;README.Rmd&#39; Writing &#39;index.html&#39; ── Building function reference ────────────────────────────────────── Updating mypackage documentation Writing NAMESPACE Loading mypackage Writing NAMESPACE Writing &#39;reference/index.html&#39; Loading mypackage Reading &#39;man/hello.Rd&#39; Writing &#39;reference/hello.html&#39; ══ DONE ═════════════════════════════════════════════════════════════ ── Previewing site ────────────────────────────────────────────────── This creates html documentation for our package in the docs/ folder. Commit and push the docs/ folder to GitHub Make the site live by enabling gh-pages. Set it to serve content from the docs folder. Your package is now installable from GitHub, has online documentation and should have this final structure: . ├── DESCRIPTION ├── LICENSE ├── LICENSE.md ├── NAMESPACE ├── R │ └── hello.R ├── README.Rmd ├── README.md ├── docs │ ├── LICENSE-text.html │ ├── LICENSE.html │ ├── authors.html │ ├── docsearch.css │ ├── docsearch.js │ ├── index.html │ ├── link.svg │ ├── pkgdown.css │ ├── pkgdown.js │ ├── pkgdown.yml │ └── reference │ ├── hello.html │ └── index.html ├── man │ └── hello.Rd ├── mypackage.Rproj └── tests ├── testthat │ └── test-hello.R └── testthat.R 6 directories, 23 files Check out my complete example here "],
["creating-a-research-compendium-with-rrtools.html", "Creating a research compendium with rrtools Background Enter the Research Compendium R community response General Project Organisation From raw to analytical data Separate function definition and application Use Rstudio projects Follow convention R Developer Tools rrtools: Research Compendia in R 💻 Workshop materials Data Workshop aims and objectives Setup 🚦 Create compendium 🚦 Update DESCRIPTION file 🚦Sharing a compendium on GitHub Create README update README 🚦 Create GitHub repository 🚦 Setting up the analysis folder Create analysis 🚦 Reproduce a paper in Rmd Setup data Inspect analysis.R file 🚦 Create journal article template using rticles 🚦 Update YAML 🚦 Add text 🚦 Update references 🚦 Update math 🚦 Add code Render final document to pdf 🚦 Add paper dependencies Final compendium", " Creating a research compendium with rrtools Background Research is increasingly computational Code and data are important research outputs yet, we still focus mainly on curating papers. Calls for openness stick: reproducibility crisis carrot: huge rewards from working open Yet we lag in conventions and technical infrastructure for such openness. Enter the Research Compendium The goal of a research compendium is to provide a standard and easily recognizable way for organizing the digital materials of a project to enable others to inspect, reproduce, and extend the research. Three Generic Principles Organize its files according to prevailing conventions: help other people recognize the structure of the project, supports tool building which takes advantage of the shared structure. Separate of data, method, and output, while making the relationship between them clear. Specify the computational environment that was used for the original analysis. R community response R packages can be used as a research compendium for organising and sharing files! R package file system structure for reproducible research Take advantage of the power of convention. Make use of great package development tools. See Ben Marwick, Carl Boettiger &amp; Lincoln Mullen (2018) Packaging Data Analytical Work Reproducibly Using R (and Friends), The American Statistician, 72:1, 80-88, DOI: &lt;10.1080/00031305.2017.1375986&gt; images: Kartik Ram: rstudio::conf 2019 talk Example use of the R package structure for a research compendium (source Marwick et al, 2018) General Project Organisation Good project layout helps ensure the Integrity of data Portability of the project Easier to pick the project back up after a break From raw to analytical data the reproducible pipeline Do not manually edit raw data Keep a clean pipeline of data processing from raw to analytical. Ideally, incorporate checks to ensure correct processing of data through to analytical. Check out rOpenSci package drake, an R-focused pipeline toolkit for reproducibility Separate function definition and application When your project is new and shiny, the script file usually contains many lines of directly executated code. As it matures, reusable chunks get pulled into their own functions. The actual analysis scripts then become relatively short, and use the functions defined in separate R scripts. Use Rstudio projects Keep your work tidy, portable and self-contained pkg here Use function here::here(&quot;path&quot;, &quot;to&quot;, &quot;file&quot;) to create robust paths relative to the project root. eg here::here(&quot;path&quot;, &quot;to&quot;, &quot;file&quot;) ## [1] &quot;/Users/Anna/Documents/workflows/workshops/books/rrresearchACCE20/path/to/file&quot; Follow convention It’s like agreeing that we will all drive on the left or the right. A hallmark of civilization is following conventions that constrain your behavior a little, in the name of public safety. Jenny Bryan on Project-oriented workflows A place for everything, everything in its place. Benjamin Franklin The benefits of following convention: You will be able to find your way around any of your projects You will be able to find your way around any project by others following same convention You will be able to find your way around any r package on GitHub! R Developer Tools Leverage tools and functionality for R package development manage dependencies make functionality available document functionality validate functionality version contol your project devtools, usethis, rrtools, Rstudio minimal analysis project An scripts/ directory that contains R scripts (.R), notebooks (.Rmd), and intermediate data. A DESCRIPTION file that provides metadata about the compendium. Most importantly, it would list the packages needed to run the analysis. Would contain field to indicate that this is an analysis, not a package. A reproducible analysis project would also contain: An R/ directory which contains R files that provide high-stakes functions. A data/ directory which contains high-stakes data. A tests/ directory that contains unit tests for the code and data. A vignettes/ directory that contains high-stakes reports. Autogenerated components: A man/ directory which contains roxygen2-generated documentation for the reusable functions and data. Online documentation in a docs/ folder. A shareable reproducible analysis project would also: Use Git + GitHub (or other public Git host) Use Travis or other continuous integration service Capture the computational environment so it can easily be recreated on a different computer. This involves at a minimum capturing package versions, but might also include capturing R version, and other external dependencies. Start small and build as necessary images: Kartik Ram: rstudio::conf 2019 talk rrtools: Research Compendia in R The goal of rrtools is to provide instructions, templates, and functions for making a basic compendium suitable for writing reproducible research with R. rrtools build on tools &amp; conventions for R package development to organise files manage dependencies share code document code check and test code rrtools extends and works with a number of R packages: devtools: functions for package development usethis: automates repetitive tasks that arise during project setup and development bookdown: facilitates writing books and long-form articles/reports with R Markdown 💻 Workshop materials Data On github: https://github.com/annakrystalli/rrtools-wkshp-materials/ click on Clone or download click on Download ZIP Unzip the file Workshop aims and objectives In this workshop we’ll use materials associated with a published paper (text, data and code) to create a research compendium around it. By the end of the workshop, you should be able to: Be able to Create a Research Compendium to manage and share resources associated with an academic publication. Be able to produce a reproducible manuscript from a single rmarkdown document. Appreciate the power of convention! Let’s dive in! Setup Install packages Next, let’s install the packages we’ll need, starting with rrtools (if you haven’t got devtools installed, you’ll need to before you can install rrtools from GitHub). # install.packages(&quot;devtools&quot;) devtools::install_github(&quot;benmarwick/rrtools&quot;) Installing rrtools imports many of the packages we’ll need today (eg, have a look at the imports section of the DESCRIPTION file). Imports: devtools, git2r, whisker, rstudioapi, rmarkdown, knitr, bookdown, curl, RCurl, jsonlite, methods, httr, usethis, clisymbols, crayon, glue, readr (&gt;= 1.1.1) Now, install some additional packages we’ll need for the workshop. install.packages(c( # source paper analysis &quot;ggthemes&quot; # bibliographic / publishing &quot;citr&quot;, &quot;rticles&quot;, # documentation &quot;roxygen2&quot;, # graphics &quot;Cairo&quot;)) Get workshop materials Today we’ll be working with a subset of materials from the published compendium of code, data, and author’s manuscript: Carl Boettiger. (2018, April 17). cboettig/noise-phenomena: Supplement to: “From noise to knowledge: how randomness generates novel phenomena and reveals information” (Version revision-2). Zenodo. http://doi.org/10.5281/zenodo.1219780 accompanying the publication: Carl Boettiger . From noise to knowledge: how randomness generates novel phenomena and reveals information. Published in Ecology Letters, 22 May 2018 https://doi.org/10.1111/ele.13085 You can download the materials using usethis::use_course() and supplying a path to a destination folder to argument destdir: usethis::use_course(url = &quot;bit.ly/rrtools_wks&quot;, destdir = &quot;~/Desktop&quot;) This will download everything we need from a GitHub repository as a .zip file, unzip it and launch it in a new Rstudio session for us to explore. Inspect materials ├── README.md &lt;- .......................repo README ├── analysis.R &lt;- ......................analysis underlying paper ├── gillespie.csv &lt;- ...................data ├── paper.pdf &lt;- .......................LaTex pdf of the paper ├── paper.txt &lt;- .......................text body of the paper ├── refs.bib &lt;- ........................bibtex bibliographic file └── rrtools-wkshp-materials.Rproj &lt;- ...rstudio project file In this workshop we’ll attempt a partial reproduction of the original paper using the materials we’ve just downloaded. We’ll use this as an opportunity to create a new research compendium using rrtools and friends! 🎊 🚦 Create compendium Now that we’ve got all the materials we need, let’s start by *creating a blank research compendium for us to work in. load library First we need to load rrtools library(rrtools) ## ✔ Git is installed on this computer, your username is annakrystalli ## ## Attaching package: &#39;rrtools&#39; ## The following objects are masked from &#39;package:usethis&#39;: ## ## use_circleci, use_readme_rmd, use_travis This performs a quick check to confirm you have Git installed and configured If you do, you should see the following output in the console. ✔ Git is installed on this computer, your username is annakrystalli create compendium Now we’re ready to create our compendium. We use function rrtools::create_compendium and supply it with a path at which our compendium will be created. The final part of our path becomes the compendium name. Because the function effectively creates a package, only a single string of lowercase alpha characters is accepted as a name. so let’s go for rrcompendium as the final part of our path. To create rrcompendium in a directory called Documents/workflows/ I use: rrtools::create_compendium(&quot;~/Documents/workflows/rrcompendium&quot;) Go ahead and create a compendium at a location of your choice. Stick with compendium name rrcompendium for ease of following the materials. If the call was successfull you should see the following console output: ✔ Setting active project to &#39;/Users/Anna/Documents/workflows/rrcompendium&#39; ✔ Creating &#39;R/&#39; ✔ Creating &#39;man/&#39; ✔ Writing &#39;DESCRIPTION&#39; ✔ Writing &#39;NAMESPACE&#39; ✔ Writing &#39;rrcompendium.Rproj&#39; ✔ Adding &#39;.Rproj.user&#39; to &#39;.gitignore&#39; ✔ Adding &#39;^rrcompendium\\\\.Rproj$&#39;, &#39;^\\\\.Rproj\\\\.user$&#39; to &#39;.Rbuildignore&#39; ✔ Opening new project &#39;rrcompendium&#39; in RStudio ✔ The package rrcompendium has been created ✔ Opening the new compendium in a new RStudio session... Next, you need to: ↓ ↓ ↓ ● Edit the DESCRIPTION file ● Use other &#39;rrtools&#39; functions to add components to the compendium and a new Rstudio session launched for the compendium: Initiate git We can initialise our compendium with .git using: usethis::use_git() N.B. Beware, you may have ended up with two Rstudio sessions of rrcompendium. Make sure to only have one session of a single project at one time to avoid problems. Inspect templates . ├── DESCRIPTION &lt;- .............................package metadata | dependency management ├── NAMESPACE &lt;- ...............................AUTO-GENERATED on build ├── R &lt;- .......................................folder for functions ├── man &lt;- .....................................AUTO-GENERATED on build └── rrcompendium.Rproj &lt;- ......................rstudio project file rrtools::create_compendium() creates the bare backbone of infrastructure required for a research compendium. At this point it provides facilities to store general metadata about our compendium (eg bibliographic details to create a citation) and manage dependencies in the DESCRIPTION file and store and document functions in the R/ folder. Together these allow us to manage, install and share functionality associated with our project. 🚦 Update DESCRIPTION file Let’s update some basic details in the DESCRIPTION file: Package: rrcompendium Title: What the Package Does (One Line, Title Case) Version: 0.0.0.9000 Authors@R: person(given = &quot;First&quot;, family = &quot;Last&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;), email = &quot;first.last@example.com&quot;) Description: What the package does (one paragraph) License: What license it uses ByteCompile: true Encoding: UTF-8 LazyData: true Title Let’s start with giving our compendium a descriptive title: Title: Partial Reproduction of Boettiger Ecology Letters 2018;21:1255–1267 with rrtools Version We don’t need to change the version now but using semantic versioning for our compendium can be a really useful way to track versions. In general, versions below 0.0.1 are in development, hence the DESCRIPTION file defaults to 0.0.0.9000. Authors Next let’s specify the author of the compendium. Edit with your own details. Authors@R: person(given = &quot;Anna&quot;, family = &quot;Krystalli&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;), email = &quot;annakrystalli@googlemail.com&quot;) For more details on specifying authors, check documentation for ?person Description Let’s add a bit more detail about the contents of the compendium in the Description. Description: This repository contains the research compendium of the partial reproduction of Boettiger Ecology Letters 2018;21:1255–1267. The compendium contains all data, code, and text associated with this sub-section of the analysis License Finally, let’s add a license for the material we create. We’ll use an MIT license. Note however that his only covers the code. We can do this with: usethis::use_mit_license() ✔ Setting License field in DESCRIPTION to &#39;MIT + file LICENSE&#39; ✔ Writing &#39;LICENSE.md&#39; ✔ Adding &#39;^LICENSE\\\\.md$&#39; to &#39;.Rbuildignore&#39; This creates files LICENSE and LICENSE.md and updates the DESCRIPTION file with details of the license. License: MIT + file LICENSE Recap We’ve finished updating our DESCRIPTION file! 🎉 It should look a bit like this: Package: rrcompendium Title: Partial Reproduction of Boettiger Ecology Letters 2018;21:1255–1267 with rrtools Version: 0.0.0.9000 Authors@R: person(given = &quot;Anna&quot;, family = &quot;Krystalli&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;), email = &quot;annakrystalli@googlemail.com&quot;) Description: This repository contains the research compendium of the partial reproduction of Boettiger Ecology Letters 2018;21:1255–1267. The compendium contains all data, code, and text associated with this sub-section of the analysis. License: MIT + file LICENSE ByteCompile: true Encoding: UTF-8 LazyData: true and your project folder should contain: . ├── DESCRIPTION ├── LICENSE ├── LICENSE.md ├── NAMESPACE ├── R ├── man └── rrcompendium.Rproj Let’s commit our work and move on to preparing our compendium for sharing on GitHub. 🚦Sharing a compendium on GitHub Create README Every GitHub repository needs a README landing page. We can create an rrtools README template using: rrtools::use_readme_rmd() ✔ Creating &#39;README.Rmd&#39; from template. ✔ Adding &#39;README.Rmd&#39; to `.Rbuildignore`. ● Modify &#39;README.Rmd&#39; ✔ Rendering README.Rmd to README.md for GitHub. ✔ Adding code of conduct. ✔ Creating &#39;CONDUCT.md&#39; from template. ✔ Adding &#39;CONDUCT.md&#39; to `.Rbuildignore`. ✔ Adding instructions to contributors. ✔ Creating &#39;CONTRIBUTING.md&#39; from template. ✔ Adding &#39;CONTRIBUTING.md&#39; to `.Rbuildignore`. This generates README.Rmd and renders it to README.md, ready to display on GitHub. It contains: a template citation to show others how to cite your project. license information for the text, figures, code and data in your compendium --- output: github_document --- &lt;!-- README.md is generated from README.Rmd. Please edit that file --&gt; ``{r, echo = FALSE} knitr::opts_chunk$set( collapse = TRUE, comment = &quot;#&gt;&quot;, fig.path = &quot;README-&quot; ) `` # rrcompendium This repository contains the data and code for our paper: &gt; Authors, (YYYY). _Title of paper_. Name of journal/book &lt;https://doi.org/xxx/xxx&gt; Our pre-print is online here: &gt; Authors, (YYYY). _Title of paper_. Name of journal/book, Accessed 30 Apr 2020. Online at &lt;https://doi.org/xxx/xxx&gt; ### How to cite Please cite this compendium as: &gt; Authors, (2020). _Compendium of R code and data for &#39;Title of paper&#39;_. Accessed 30 Apr 2020. Online at &lt;https://doi.org/xxx/xxx&gt; ### How to download or install You can download the compendium as a zip from from this URL: &lt;/archive/master.zip&gt; Or you can install this compendium as an R package, rrcompendium, from GitHub with: ### Licenses **Text and figures :** [CC-BY-4.0](http://creativecommons.org/licenses/by/4.0/) **Code :** See the [DESCRIPTION](DESCRIPTION) file **Data :** [CC-0](http://creativecommons.org/publicdomain/zero/1.0/) attribution requested in reuse ### Contributions We welcome contributions from everyone. Before you get started, please see our [contributor guidelines](CONTRIBUTING.md). Please note that this project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project you agree to abide by its terms. The call also adds two other markdown files: CONDUCT.md: a code of conduct for users CONTRIBUTING.md:: basic instructions for people who want to contribute to our compendium update README There’s five main edits we need to make to the template: edit compendium DOI details Although we don’t have a link to the DOI, we can complete the rest of the details and leave it as a place holder. This repository contains the data and code for our reproduction paper: &gt; Krystalli, A, (2018). _Partial Reproduction of Boettiger Ecology Letters 2018;21:1255–1267 with rrtools_. &lt;https://doi.org/{DOI-to-paper}&gt; edit paper.pdf DOI Our reproduction pre-print is online here: &gt; Krystalli, A, (2018). _Partial Reproduction of Boettiger Ecology Letters 2018;21:1255–1267 with rrtools_, Accessed 30 Apr 2020. Online at &lt;https://doi.org/{DOI-to-compendium}&gt; edit compendium citation Please cite this compendium as: &gt; Krystalli, A, (2020). _Compendium of R code and data for &#39;Partial Reproduction of Boettiger Ecology Letters 2018;21:1255–1267 with rrtools&#39;_. Accessed 30 Apr 2020. Online at &lt;https://doi.org/{DOI-to-compendium}&gt; update zip url This is a link to download a zipped file of the repository. To update the template, just paste the url of your compendium repository like so: ### How to download or install You can download the compendium as a zip from from this URL: &lt;https://github.com/annakrystalli/rrcompendium/archive/master.zip&gt; adjust data LICENSE Let’s adjust the data LICENSE to match the source compendium license, which is CC-BY 4.0. Let’s also add Carl Boettiger as copyright holder of the data. **Text and figures :** [CC-BY-4.0](http://creativecommons.org/licenses/by/4.0/), Copyright (c) 2018 Carl Boettiger. **Code :** See the [DESCRIPTION](DESCRIPTION) file **Data :** [CC-BY-4.0](http://creativecommons.org/licenses/by/4.0/), Copyright (c) 2018 Carl Boettiger. Remember to knit your README.Rmd to it’s .md version. 🚦 Create GitHub repository Next, we’ll create a GitHub repository to share our compendium. We’ll make use of our GITHUB_PAT and go for https authentication. We can do this with function: usethis::use_github(protocol = &quot;https&quot;) ✔ Setting active project to &#39;/Users/Anna/Documents/workflows/rrcompendium&#39; ● Check title and description Name: rrcompendium Description: Partial Reproduction of Boettiger Ecology Letters 2018;21:1255–1267 with rrtools The function will prompt you to confirm the name and description for your GitHub repo which it parses from our DESCRIPTION file. If everything looks good select the affirmative option. Are title and description ok? 1: Not now 2: Definitely 3: Nope If creation of the repo was successfull you should see the following console output: ✔ Creating GitHub repository ✔ Adding GitHub remote ✔ Adding GitHub links to DESCRIPTION ✔ Setting URL field in DESCRIPTION to &#39;https://github.com/annakrystalli/rrcompendium&#39; ✔ Setting BugReports field in DESCRIPTION to &#39;https://github.com/annakrystalli/rrcompendium/issues&#39; ✔ Pushing to GitHub and setting remote tracking branch ✔ Opening URL https://github.com/annakrystalli/rrcompendium Commit and push to GitHub We’ve now completed our rrtools README.Rmd! 🎉 Render it to update the README.md file which is displayed on GitHub Commit and push to GitHub. You’re Github repository README should look like this on the site: and your project folder should contain: . ├── CONDUCT.md ├── CONTRIBUTING.md ├── DESCRIPTION ├── LICENSE ├── LICENSE.md ├── NAMESPACE ├── R ├── README.Rmd ├── README.md ├── man └── rrcompendium.Rproj 🚦 Setting up the analysis folder Create analysis We now need an analysis folder to contain our analysis and paper. We can do this using function rrtools::use_analysis() The function has three location = options: top_level to create a top-level analysis/ directory inst to create an inst/ directory (so that all the sub-directories are available after the package is installed) vignettes to create a vignettes/ directory (and automatically update the DESCRIPTION). The default is a top-level analysis/. rrtools::use_analysis() ✔ Adding bookdown to Imports ✔ Creating &#39;analysis&#39; directory and contents ✔ Creating &#39;analysis&#39; ✔ Creating &#39;analysis/paper&#39; ✔ Creating &#39;analysis/figures&#39; ✔ Creating &#39;analysis/templates&#39; ✔ Creating &#39;analysis/data&#39; ✔ Creating &#39;analysis/data/raw_data&#39; ✔ Creating &#39;analysis/data/derived_data&#39; ✔ Creating &#39;references.bib&#39; from template. ✔ Creating &#39;paper.Rmd&#39; from template. Next, you need to: ↓ ↓ ↓ ↓ ● Write your article/report/thesis, start at the paper.Rmd file ● Add the citation style library file (csl) to replace the default provided here, see https://github.com/citation-style-language/ ● Add bibliographic details of cited items to the &#39;references.bib&#39; file ● For adding captions &amp; cross-referencing in an Rmd, see https://bookdown.org/yihui/bookdown/ ● For adding citations &amp; reference lists in an Rmd, see http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html Note that: ⚠ Your data files are tracked by Git and will be pushed to GitHub Regardless for location option, the contents of the created sub-directories are the same: analysis/ | ├── paper/ │ ├── paper.Rmd # this is the main document to edit │ └── references.bib # this contains the reference list information ├── figures/ # location of the figures produced by the Rmd | ├── data/ │ ├── DO-NOT-EDIT-ANY-FILES-IN-HERE-BY-HAND │ ├── raw_data/ # data obtained from elsewhere │ └── derived_data/ # data generated during the analysis | └── templates ├── journal-of-archaeological-science.csl | # this sets the style of citations &amp; reference list ├── template.docx # used to style the output of the paper.Rmd └── template.Rmd Let’s inspect paper.Rmd paper.Rmd is ready to write in and render with bookdown. It includes: a YAML header that identifies the references.bib file and the supplied csl file (Citation Style Language) to style the reference list) a colophon that adds some git commit details to the end of the document. This means that the output file (HTML/PDF/Word) is always traceable to a specific state of the code. references.bib The references.bib file has just one item to demonstrate the format. It is ready to insert more reference details. We can replace the supplied csl file with a different citation style from https://github.com/citation-style-language/ 🚦 Reproduce a paper in Rmd In this section we’re going to create a literate programming document to reproduce the paper in a format suitable for journal submission or as a pre-print. We’ll do this using the course materials we downloaded. In particular, we’re going to combine the code in analysis.R, the text in paper.txt and the references in the refs.bib file in an .Rmd document to reproduce paper.pdf. More information on working on academic journals with Bookdown Setup data Copy data to data/ To begin, let’s copy gillespie.csv from the course materials you downloaded in rrtools-wkshp-materials-master/ to the subfolder analysis/data/raw_data/ in rrcompendium Your data folder should now look like this: analysis/data ├── DO-NOT-EDIT-ANY-FILES-IN-HERE-BY-HAND ├── derived_data └── raw_data └── gillespie.csv Inspect analysis.R file Let’s also open analysis.R in the course materials and run the code. The script has some initial setup, then loads the data, recodes one of the columns for plotting and then plots the results of the simulation, which generates figure 1 in paper.pdf. analysis.R library(dplyr) library(readr) library(ggplot2) library(ggthemes) theme_set(theme_grey()) # load-data data &lt;- read_csv(here::here(&quot;gillespie.csv&quot;), col_types = &quot;cdiddd&quot;) # create colour palette colours &lt;- ptol_pal()(2) # recode-data data &lt;- data %&gt;% mutate(system_size = recode(system_size, large = &quot;A. 1000 total sites&quot;, small = &quot;B. 100 total sites&quot;)) # plot-gillespie data %&gt;% ggplot(aes(x = time)) + geom_hline(aes(yintercept = mean), lty=2, col=colours[2]) + geom_hline(aes(yintercept = minus_sd), lty=2, col=colours[2]) + geom_hline(aes(yintercept = plus_sd), lty=2, col=colours[2]) + geom_line(aes(y = n), col=colours[1]) + facet_wrap(~system_size, scales = &quot;free_y&quot;) 🚦 Create journal article template using rticles The rticles package is designed to simplify the creation of documents that conform to submission standards. A suite of custom R Markdown templates for popular journals is provided by the package. delete paper/ subdirectory First, let’s delete the current analysis/paper folder as we’re going to create a new paper.Rmd template. create new paper template This particular paper was published in Ecology Letters, an Elsevier Journal. We can create a new paper.Rmd template from the templates provided by rticles package. We can use the New R Markdown dialog Select: Template: Elesevier Journal Article Name: paper Location: ~/Documents/workflows/rrcompendium/analysis Or we can use rmarkdown::draft() to create articles: rmarkdown::draft(here::here(&quot;analysis&quot;,&quot;paper.Rmd&quot;), template = &quot;elsevier_article&quot;, package = &quot;rticles&quot;) Both these functions create the following files in a new directory analysis/paper. analysis/paper ├── elsarticle.cls ├── mybibfile.bib ├── numcompress.sty └── paper.Rmd The elsarticle.cls contains contains the citation language style for the references. The mybibfile.bib contains an example reference list. The new paper.Rmd is the file we will be working in. Let’s open it up and start editing it. 🚦 Update YAML The YAML header in Paper.Rmd contains document wide metadata and is pre-populated with some fields relevant to an academic publication. --- title: Short Paper author: - name: Alice Anonymous email: alice@example.com affiliation: Some Institute of Technology footnote: Corresponding Author - name: Bob Security email: bob@example.com affiliation: Another University address: - code: Some Institute of Technology address: Department, Street, City, State, Zip - code: Another University address: Department, Street, City, State, Zip abstract: | This is the abstract. It consists of two paragraphs. journal: &quot;An awesome journal&quot; date: &quot;2020-04-30&quot; bibliography: mybibfile.bib output: rticles::elsevier_article --- Here we’re going to reproduce paper.pdf as is, so we’ll actually be editing the file with details from the original publication. First, let’s clear all text BELOW the YAML header (which is delimited by ---. DO NOT delete the YAML header). Next, let’s open paper.txt from the course material which contains all text from the in paper.pdf. We can use it to complete some of the fields in the YAML header. title Add the paper title to this field title: &quot;From noise to knowledge: how randomness generates novel phenomena and reveals information&quot; author Here we specify author details. author: - name: &quot;Carl Boettiger&quot; affiliation: a email: &quot;cboettig@berkeley.edu&quot; address Here we specify the addresses associated with the affiliations specified in authors address: - code: a address: &quot;Dept of Environmental Science, Policy, and Management, University of California Berkeley, Berkeley CA 94720-3114, USA&quot; Note that the field code in address cross-references with the affiliations specified in author. bibliography Before specifying the bibliography, we need to copy the refs.bib file associated with paper.pdf from the course materials and save it in our analysis/paper subdirectory. Next we can set the refs.bib as the source for our paper’s bibliograpraphy: bibliography: refs.bib 🚦 layout We can add an additional field called layout which specifies the layout of the output and takes the following values. review: doublespace margins 3p: singlespace margins 5p: two-column Let’s use singlespace margins layout: 3p preamble We can add also an additional field called preamble. This allows us to include LaTeX packages and functions. We’ll use the following to add linenumbers and doublespacing. preamble: | \\usepackage[nomarkers]{endfloat} \\linenumbers \\usepackage{setspace} \\doublespacing 🚦 abstract This field should contain the abstract abstract: | # Abstract Noise, as the term itself suggests, is most often seen a nuisance to ecological insight, a inconvenient reality that must be acknowledged, a haystack that must be stripped away to reveal the processes of interest underneath. Yet despite this well-earned reputation, noise is often interesting in its own right: noise can induce novel phenomena that could not be understood from some underlying determinstic model alone. Nor is all noise the same, and close examination of differences in frequency, color or magnitude can reveal insights that would otherwise be inaccessible. Yet with each aspect of stochasticity leading to some new or unexpected behavior, the time is right to move beyond the familiar refrain of &quot;everything is important&quot; (Bjørnstad &amp; Grenfell 2001). Stochastic phenomena can suggest new ways of inferring process from pattern, and thus spark more dialog between theory and empirical perspectives that best advances the field as a whole. I highlight a few compelling examples, while observing that the study of stochastic phenomena are only beginning to make this translation into empirical inference. There are rich opportunities at this interface in the years ahead. output The output format. In this case, the template is correctly pre-populated with rticles::elsevier_article so no need to edit. output: rticles::elsevier_article 🚦 Add text Now let’s add the main body of the paper from paper.txt. add new page after abstract First, let’s a add a new page after the abstract using: \\newpage copy and paste text from paper.txt We do not need the details we’ve just completed the YAML with, so ignore the title, abstract etc and just copy everything in paper.txt from the Introduction header down to and including the reference section header. # Introduction: Noise the nuisance To many, stochasticity, or more simply, noise, is just that -- something which obscures patterns we are ... ... ... ... ... # Acknowledgements The author acknowledges feedback and advice from the editor, Tim Coulson and two anonymous reviewers. This work was supported in part by USDA National Institute of Food and Agriculture, Hatch project CA-B-INS-0162-H. # References Check pdf output Let’s knit our document and have our first look at the resulting pdf by clicking on the Knit tab. 🚦 Update references Next we’ll replace the flat citations in the text with real linked citation which can be used to auto-generate formatted inline citations and the references section. Insert formatted citations We’ll use the citr package, which provides functions and an RStudio addin to search a BibTeX-file to create and insert formatted Markdown citations into the current document. Once citr is installed and you have restarted your R session, the addin appears in the addin menu. The addin will automatically look up the Bib(La)TeX-file(s) specified in the YAML front matter. To insert a citation Select text to replace with a citation Launch citr addin: Search for citation to insert Select citation to insert Insert citation Carry on updating the rest of the citations. Don’t forget to check the abstract for citations! 🚦 Update math For the sake of time today, and not to open this topic too deeply here, I’ve included the following LaTex equation syntax in the text: \\begin{align} \\frac{\\mathrm{d} n}{\\mathrm{d} t} = \\underbrace{c n \\left(1 - \\frac{n}{N}\\right)}_{\\textrm{birth}} - \\underbrace{e n}_{\\textrm{death}}, \\label{levins} \\end{align} that generates equation 1 in the paper.pdf. \\[\\begin{align} \\frac{\\mathrm{d} n}{\\mathrm{d} t} = \\underbrace{c n \\left(1 - \\frac{n}{N}\\right)}_{\\textrm{birth}} - \\underbrace{e n}_{\\textrm{death}}, \\label{levins} \\end{align}\\] So you don’t need to edit anything here. Check Math expressions and Markdown extensions by bookdown for more information. update inline math Inline LaTeX equations and parameters can be written between a pair of dollar signs using the LaTeX syntax, e.g., $f(x) = 1/x$ generates \\(f(x) = 1/x\\). Using paper.pdf to identify mathematical expressions in the text (generally they appear in italic), edit your paper.Rmd, enclosing them between dollar signs. Check pdf output Let’s knit our document to check our references and maths annotations have been updated correctly by clicking on the Knit tab. 🚦 Add code Now that we’ve set up the text for our paper, let’s insert the code to generate figure 1. Add libraries chunk First let’s insert a libraries code chunk right at the top of the document to set up our analysis. Because it’s a setup chunk we set include = F which suppresses all output resulting from chunk evaluation. ```{r libraries, include=FALSE} ``` set document chunk options Now, let’s set some knitr options for the whole document by adding the following code to our libraries chunk: knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, dev=&quot;cairo_pdf&quot;, fig.width=7, fig.height=3.5) We’re setting default chunk options to: echo = FALSE message = FALSE warning = FALSE to suppress code, warnings and messages in the output, and dev=&quot;cairo_pdf&quot; fig.width=7 fig.height=3.5 to specify how figures will appear. add libraries Copy and paste the code for loading all the libraries from analysis.R. Add library rrcompendium so we can access function recode_system_size. The libraries chunk should now look like so: knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, dev=&quot;cairo_pdf&quot;, fig.width=7, fig.height=3.5) library(dplyr) library(readr) library(ggplot2) library(ggthemes) library(rrcompendium) Add set-theme chunk Right below the libraries chunk, insert a new chunk and call it set-theme Copy the code to set the plot theme and pasted into the set-theme code: theme_set(theme_grey()) Add figure1 chunk Now scroll down towards the bottom of the document and create a new chunk just above the Conclusions section. Call it figure1 Add code Copy and paste the remaining code into a new chunk which will create figure 1. # create colour palette colours &lt;- ptol_pal()(2) # load-data data &lt;- read_csv(here::here(&quot;gillespie.csv&quot;), col_types = &quot;cdiddd&quot;) # recode-data data &lt;- data %&gt;% mutate(system_size = recode(system_size, large = &quot;A. 1000 total sites&quot;, small= &quot;B. 100 total sites&quot;)) # plot-gillespie data %&gt;% ggplot(aes(x = time)) + geom_hline(aes(yintercept = mean), lty=2, col=colours[2]) + geom_hline(aes(yintercept = minus_sd), lty=2, col=colours[2]) + geom_hline(aes(yintercept = plus_sd), lty=2, col=colours[2]) + geom_line(aes(y = n), col=colours[1]) + facet_wrap(~system_size, scales = &quot;free_y&quot;) 🚦 Add caption Finally, let’s update chunk figure1 to include a figure caption. The text for the caption is at the bottom of paper.txt. We can include it in the chunk header through chunk option fig.cap like so: ```{r figure1, figure1, fig.cap=&quot;Population dynamics from a Gillespie simulation of the Levins model with large (N=1000, panel A) and small (N=100, panel B) number of sites (blue) show relatively weaker effects of demographic noise in the bigger system. Models are otherwise identical, with e = 0.2 and c = 1 (code in appendix A). Theoretical predictions for mean and plus/minus one standard deviation shown in horizontal re dashed lines.&quot;} ``` Render final document to pdf Let’s check our final work by re-knitting to pdf. You should be looking at something that looks a lot like paper.pdf 🚦 Add paper dependencies Finally, before we’re finished, let’s ensure the dependencies introduced in the paper are included. We can use rrtools::add_dependencies_to_description() rrtools::add_dependencies_to_description() This function scans script files (.R, .Rmd, .Rnw, .Rpres, etc.) for external package dependencies indicated by library(), require() or :: and adds those packages to the Imports field in the package DESCRIPTION: Imports: bookdown, dplyr, ggplot2 (&gt;= 3.0.0), ggthemes (&gt;= 3.5.0), here (&gt;= 0.1), knitr (&gt;= 1.20), rticles (&gt;= 0.6) 🔨 Install and Restart Commit and push to GitHub! Final compendium You can see the resulting rrcompendium here The complete compendium should contain the following files: . ├── CONDUCT.md ├── CONTRIBUTING.md ├── DESCRIPTION ├── LICENSE ├── LICENSE.md ├── NAMESPACE ├── R │ └── process-data.R ├── README.Rmd ├── README.md ├── analysis │ ├── data │ │ ├── DO-NOT-EDIT-ANY-FILES-IN-HERE-BY-HAND │ │ ├── derived_data │ │ └── raw_data │ │ └── gillespie.csv │ ├── figures │ ├── paper │ │ ├── elsarticle.cls │ │ ├── mybibfile.bib │ │ ├── numcompress.sty │ │ ├── paper.Rmd │ │ ├── paper.fff │ │ ├── paper.pdf │ │ ├── paper.spl │ │ ├── paper.tex │ │ ├── paper_files │ │ │ └── figure-latex │ │ │ └── figure1-1.pdf │ │ └── refs.bib │ └── templates │ ├── journal-of-archaeological-science.csl │ ├── template.Rmd │ └── template.docx ├── inst │ └── testdata │ └── gillespie.csv ├── man │ └── recode_system_size.Rd ├── rrcompendium.Rproj └── tests ├── testthat │ └── test-process-data.R └── testthat.R "],
["about.html", "About Acknowledgements", " About This course is funded by NERC through the ACCE Doctoral Partnership program It started in 2015 by Dr. Tom Webb &amp; Dr. Anna Krystalli from the University of Sheffield and has been continued since 2016 by Anna Krystalli. Since then it has gone from a one day course on Data management to a two day course, encompassing project management, version control and literate programming. It is aimed at preparing first year PhD students for managing their research code and data successfully, in line with shifting expectations on reproducibility, interoperability, accessibility and archiving of research materials. Acknowledgements A number of images image were created by Scriberia for The Turing Way community and are used under a CC-BY licence. "],
["setup.html", "Software Setup Software Requirements", " Software Setup Software Requirements This workshop assumes you have the R, RStudio and Git and Bash Shell software installed on your computer and a personal GitHub account. You will also need some geospatial system libraries installed. R R can be downloaded here. RStudio RStudio is an environment for developing using R. It can be downloaded here. You will need the Desktop version (&gt; 1.0) for your computer. The Bash Shell Bash is a commonly-used shell that gives you the power to do simple tasks more quickly. Windows Video Tutorial Download the Git for Windows installer. Run the installer and follow the steps bellow: Click on “Next”. Click on “Next”. Keep “Use Git from the Windows Command Prompt” selected and click on “Next”. If you forgot to do this programs that you need for the workshop will not work properly. If this happens rerun the installer and select the appropriate option. Click on “Next”. Keep “Checkout Windows-style, commit Unix-style line endings” selected and click on “Next”. Keep “Use Windows’ default console window” selected and click on “Next”. Click on “Install”. Click on “Finish”. If your “HOME” environment variable is not set (or you don’t know what this is): Open command prompt (Open Start Menu then type cmd and press [Enter]) Type the following line into the command prompt window exactly as shown: setx HOME “%USERPROFILE%” Press [Enter], you should see SUCCESS: Specified value was saved. Quit command prompt by typing exit then pressing [Enter] This will provide you with both Git and Bash in the Git Bash program. Mac OS X The default shell in all versions of Mac OS X is Bash, so no need to install anything. You access Bash from the Terminal (found in /Applications/Utilities). See the Git installation video tutorial for an example on how to open the Terminal. Linux The default shell is usually Bash, but if your machine is set up differently you can run it by opening a terminal and typing bash. There is no need to install anything. Geospatial Libraries Some of the workflows require geospatial packages like sf and have additional system requirements. Follow the installation instructions in sf package documentation according to your operating system. Git &amp; GitHub Required for the Version Control part of the the course Git is a version control system that lets you track who made changes to what when and has options for easily updating a shared or public version of your code on github.com. You will need a supported web browser (current versions of Chrome, Firefox or Safari, or Internet Explorer version 9 or above). You will also need an account at github.com. Basic GitHub accounts are free. We encourage you to create a GitHub account if you don’t have one already. Please consider what personal information you’d like to reveal. For example, you may want to review these instructions for keeping your email address private provided at GitHub. Windows Git should be installed on your computer as part of your Bash install (described above). Mac OS X Video Tutorial For OS X 10.9 and higher, install Git for Mac by downloading and running the most recent “mavericks” installer from this list. After installing Git, there will not be anything in your /Applications folder, as Git is a command line program. For older versions of OS X (10.5-10.8) use the most recent available installer labelled “snow-leopard” available here. Linux If Git is not already available on your machine you can try to install it via your distro’s package manager. For Debian/Ubuntu run sudo apt-get install git and for Fedora run sudo yum install git. Research Compendium Exercise For the final practical sessions, we will need to use LaTeX. If you don’t have LaTeX installed, consider installing TinyTeX, a custom LaTeX distribution based on TeX Live that is small in size but functions well in most cases, especially for R users. install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() Check docs before before installing. devtools requirements You might also need a set of development tools to install and run devtools. On Windows, download and install Rtools, and devtools takes care of the rest. On Mac, install the Xcode command line tools. On Linux, install the R development package, usually called r-devel or r-base-dev. Install R dependecies To be able to run materials locally, you will also need to install all the required R packages. Run the code in install.R FAQs 1. Are there any advantages or disadvantages to setting up a github account with our university email address? Is it possible to change emails say when we finish our PhD? I personally prefer to use a non-institutional email for registering accounts to platforms I want smooth access to regardless of affiliation. However, there are advantages associated with affiliation with an academic institution on GitHub, namely that you get a free developer account. The most important benefit of that is that it gives you unlimited public AND private repositories. You can however add your academic email as a secondary email which will allow you to benefit from this academic research discount. You can also just use your academic address from the start and just change it once you move on. Find out more about claiming an academic discount here. "],
["solutions.html", "Solutions Part I", " Solutions Part I List subsetting challenge xlist$b[2] ## [1] 2 xlist[[2]][2] ## [1] 2 xlist[[&quot;b&quot;]][2] ## [1] 2 "]
]
